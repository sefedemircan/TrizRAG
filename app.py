import streamlit as st
import chromadb
from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction
import openai
from sentence_transformers import SentenceTransformer
import numpy as np
import hashlib
import time
import json
from typing import List, Dict, Any, Tuple
import requests
import os
from datetime import datetime
from dotenv import load_dotenv
import pandasai as pai
from pandasai_litellm.litellm import LiteLLM
import pandas as pd
from pandasai import SmartDataframe

# .env dosyasÄ±nÄ± yÃ¼kle
load_dotenv()

# pandasai konfigÃ¼rasyonu
def setup_pandasai():
    """pandasai iÃ§in LiteLLM konfigÃ¼rasyonu"""
    try:
        openrouter_api_key = os.getenv("OPENROUTER_API_KEY")
        if openrouter_api_key:
            # OpenRouter API key'i environment variable olarak ayarla
            os.environ["OPENROUTER_API_KEY"] = openrouter_api_key
            
            # LiteLLM ile LLM oluÅŸtur
            llm = LiteLLM(model="openrouter/mistralai/mistral-small-3.1-24b-instruct:free")
            
            # pandasai konfigÃ¼rasyonu - verilen Ã¶rnekteki gibi
            pai.config.set({
                "llm": llm
            })
            
            return True
        else:
            st.warning("âš ï¸ pandasai iÃ§in OPENROUTER_API_KEY bulunamadÄ±")
            return False
    except Exception as e:
        st.error(f"pandasai konfigÃ¼rasyon hatasÄ±: {e}")
        return False

# Sayfa konfigÃ¼rasyonu
st.set_page_config(
    page_title="TrizRAG - AI-Powered Document Intelligence",
    page_icon="ğŸš€",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS stilleri
st.markdown("""
<style>
    .main-header {
        background: #ff4a4a;
        padding: 2rem;
        border-radius: 15px;
        margin-bottom: 2rem;
        text-align: center;
        color: white;
    }
    
    .main-header h1 {
        font-size: 3rem;
        font-weight: 700;
        margin-bottom: 0.5rem;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
    }
    
    .main-header p {
        font-size: 1.2rem;
        opacity: 0.9;
        margin-bottom: 0;
    }
    
    .feature-card {
        background: #ff4a4a;
        padding: 1.5rem;
        border-radius: 10px;
        border: 1px solid #e0e0e0;
        box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        margin-bottom: 1rem;
    }
    
    .status-indicator {
        display: inline-block;
        width: 12px;
        height: 12px;
        border-radius: 50%;
        margin-right: 8px;
    }
    
    .status-connected { background-color: #4CAF50; }
    .status-disconnected { background-color: #f44336; }
    .status-loading { background-color: #ff9800; }
    
    .metric-card {
        background: #ff4a4a;
        color: white;
        padding: 1rem;
        border-radius: 10px;
        text-align: center;
        margin: 0.5rem 0;
    }
    
    .help-tooltip {
        
        border-left: 4px solid #ff4a4a;
        padding: 1rem;
        margin: 1rem 0;
        border-radius: 5px;
    }
    
    .success-message {
        background-color: #d4edda;
        border: 1px solid #c3e6cb;
        color: #155724;
        padding: 1rem;
        border-radius: 5px;
        margin: 1rem 0;
    }
    
    .error-message {
        background-color: #f8d7da;
        border: 1px solid #f5c6cb;
        color: #721c24;
        padding: 1rem;
        border-radius: 5px;
        margin: 1rem 0;
    }
    
    .warning-message {
        background-color: #fff3cd;
        border: 1px solid #ffeaa7;
        color: #856404;
        padding: 1rem;
        border-radius: 5px;
        margin: 1rem 0;
    }
    
    .tab-content {
        padding: 1rem 0;
    }
    
    .upload-area {
        border: 1px solid;
        border-radius: 10px;
        padding: 2rem;
        text-align: center;
        transition: all 0.3s ease;
    }
    
    .upload-area:hover {
        border-color: #ff4a4a;
        background-color: #ff4a4a;
        transition: all 0.5s ease;
    }
    }
</style>
""", unsafe_allow_html=True)


class AdvancedRAGSystem:
    def __init__(self):
        self.embedding_model = None
        self.client = None
        self.collection = None
        self.collection_name = "rag-poc-collection"
        # OpenRouter API key'i .env'den otomatik al
        self.openrouter_api_key = os.getenv("OPENROUTER_API_KEY")
        self.dimension = 384  # all-MiniLM-L6-v2 embedding boyutu
        self.chroma_api_key = os.getenv("CHROMA_API_KEY")
        self.chroma_tenant = os.getenv("CHROMA_TENANT")
        self.chroma_database = os.getenv("CHROMA_DATABASE")
        # pandasai iÃ§in DataFrame'ler
        self.dataframes = {}
        self.pandasai_configured = False

    def initialize_chromadb(self):
        """ChromaDB Cloud'u baÅŸlat"""
        try:
            # ChromaDB Cloud client'Ä± baÅŸlat
            self.client = chromadb.HttpClient(
                ssl=True,
                host='api.trychroma.com',
                tenant=self.chroma_tenant,
                database=self.chroma_database,
                headers={
                    'x-chroma-token': self.chroma_api_key
                }
            )
            
            # Embedding function oluÅŸtur
            embedding_function = SentenceTransformerEmbeddingFunction(
                model_name='all-MiniLM-L6-v2'
            )
            
            # Collection'Ä± oluÅŸtur veya al
            try:
                self.collection = self.client.get_collection(
                    name=self.collection_name,
                    embedding_function=embedding_function
                )
            except:
                self.collection = self.client.create_collection(
                    name=self.collection_name,
                    embedding_function=embedding_function
                )
            
            return True

        except Exception as e:
            st.error(f"ChromaDB Cloud baÄŸlantÄ± hatasÄ±: {e}")
            return False

    def initialize_pandasai(self):
        """pandasai'Ä± baÅŸlat"""
        try:
            self.pandasai_configured = setup_pandasai()
            return self.pandasai_configured
        except Exception as e:
            st.error(f"pandasai baÅŸlatma hatasÄ±: {e}")
            return False

    def add_dataframe(self, name: str, df: pd.DataFrame) -> bool:
        """DataFrame ekle"""
        try:
            # pandasai DataFrame'i olarak oluÅŸtur
            # Ã–nce CSV olarak kaydet, sonra pandasai ile oku
            import tempfile
            import os
            
            with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False) as tmp_file:
                df.to_csv(tmp_file.name, index=False)
                tmp_path = tmp_file.name
            
            # pandasai ile CSV'yi oku
            pai_df = pai.read_csv(tmp_path)
            
            # GeÃ§ici dosyayÄ± sil
            os.unlink(tmp_path)
            
            # pandasai DataFrame'i sakla
            self.dataframes[name] = pai_df
            return True
        except Exception as e:
            st.error(f"DataFrame ekleme hatasÄ±: {e}")
            return False

    def get_dataframe(self, name: str):
        """DataFrame getir"""
        return self.dataframes.get(name)

    def list_dataframes(self) -> List[str]:
        """Mevcut DataFrame'lerin listesini getir"""
        return list(self.dataframes.keys())

    def chat_with_dataframe(self, df_name: str, query: str) -> str:
        """DataFrame ile sohbet et"""
        if not self.pandasai_configured:
            return "âŒ pandasai henÃ¼z yapÄ±landÄ±rÄ±lmadÄ±!"
        
        if df_name not in self.dataframes:
            return f"âŒ '{df_name}' adÄ±nda DataFrame bulunamadÄ±!"
        
        try:
            df = self.dataframes[df_name]
            # Verilen Ã¶rnekteki gibi basit pandasai kullanÄ±mÄ±
            response = df.chat(query)
            return str(response)
        except Exception as e:
            return f"âŒ DataFrame sohbet hatasÄ±: {e}"

    def analyze_dataframe(self, df_name: str) -> Dict:
        """DataFrame analizi"""
        if df_name not in self.dataframes:
            return {"error": f"'{df_name}' adÄ±nda DataFrame bulunamadÄ±!"}
        
        try:
            pai_df = self.dataframes[df_name]
            # pandasai DataFrame'den orijinal pandas DataFrame'i al
            df = pai_df._df if hasattr(pai_df, '_df') else pai_df
            
            analysis = {
                "shape": df.shape,
                "columns": list(df.columns),
                "dtypes": df.dtypes.to_dict(),
                "missing_values": df.isnull().sum().to_dict(),
                "numeric_columns": df.select_dtypes(include=[np.number]).columns.tolist(),
                "categorical_columns": df.select_dtypes(include=['object']).columns.tolist(),
                "sample_data": df.head(5).to_dict('records')
            }
            return analysis
        except Exception as e:
            return {"error": f"Analiz hatasÄ±: {e}"}

    @st.cache_resource
    def load_embedding_model(_self):
        """Embedding modelini yÃ¼kle"""
        try:
            _self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
            return True
        except Exception as e:
            st.error(f"Embedding model yÃ¼kleme hatasÄ±: {e}")
            return False

    def chunk_text(self, text: str, chunk_size: int = 500, overlap: int = 50) -> List[str]:
        """Metni parÃ§alara bÃ¶l"""
        chunks = []
        start = 0
        text_length = len(text)

        while start < text_length:
            end = start + chunk_size
            if end > text_length:
                end = text_length

            chunk = text[start:end]
            chunks.append(chunk.strip())

            if end == text_length:
                break

            start = end - overlap

        return [chunk for chunk in chunks if len(chunk.strip()) > 10]

    def generate_id(self, text: str) -> str:
        """Metin iÃ§in benzersiz ID Ã¼ret"""
        return hashlib.md5(text.encode()).hexdigest()

    def upsert_documents(self, documents: List[str], metadata_list: List[Dict] = None) -> bool:
        """DÃ¶kÃ¼manlarÄ± ChromaDB'ye ekle"""
        if not self.collection:
            return False

        try:
            all_ids = []
            all_documents = []
            all_metadatas = []

            with st.spinner("DÃ¶kÃ¼manlar iÅŸleniyor ve vektÃ¶rleÅŸtiriliyor..."):
                for i, doc in enumerate(documents):
                    # Metni parÃ§alara bÃ¶l
                    chunks = self.chunk_text(doc)

                    for j, chunk in enumerate(chunks):
                        # ID oluÅŸtur
                        chunk_id = f"doc_{i}_chunk_{j}_{self.generate_id(chunk)[:8]}"

                        # Metadata hazÄ±rla
                        metadata = {
                            "doc_id": i,
                            "chunk_id": j,
                            "timestamp": datetime.now().isoformat(),
                            "length": len(chunk)
                        }

                        if metadata_list and i < len(metadata_list):
                            metadata.update(metadata_list[i])

                        all_ids.append(chunk_id)
                        all_documents.append(chunk)
                        all_metadatas.append(metadata)

            # ChromaDB'ye ekle
            self.collection.add(
                ids=all_ids,
                documents=all_documents,
                metadatas=all_metadatas
            )

            return True

        except Exception as e:
            st.error(f"DÃ¶kÃ¼man ekleme hatasÄ±: {e}")
            return False

    def search_similar(self, query: str, top_k: int = 5, score_threshold: float = 0.5, search_type: str = "semantic") -> List[Dict]:
        """Benzer dÃ¶kÃ¼manlarÄ± ara"""
        if not self.collection:
            return []

        try:
            if search_type == "semantic":
                # Semantic search - embedding tabanlÄ±
                results = self.collection.query(
                    query_texts=[query],
                    n_results=top_k,
                    include=["documents", "metadatas", "distances"]
                )
            elif search_type == "keyword":
                # Keyword search - where clause ile
                results = self.collection.query(
                    query_texts=[query],
                    n_results=top_k,
                    where={"$or": [{"text": {"$contains": word}} for word in query.lower().split() if len(word) > 2]},
                    include=["documents", "metadatas", "distances"]
                )
            elif search_type == "hybrid":
                # Hybrid search - hem semantic hem keyword
                semantic_results = self.collection.query(
                    query_texts=[query],
                    n_results=top_k * 2,  # Daha fazla sonuÃ§ al
                    include=["documents", "metadatas", "distances"]
                )
                
                keyword_results = self.collection.query(
                    query_texts=[query],
                    n_results=top_k * 2,
                    where={"$or": [{"text": {"$contains": word}} for word in query.lower().split() if len(word) > 2]},
                    include=["documents", "metadatas", "distances"]
                )
                
                # SonuÃ§larÄ± birleÅŸtir ve sÄ±rala
                all_results = []
                
                # Semantic sonuÃ§larÄ± ekle
                if semantic_results['documents'] and semantic_results['documents'][0]:
                    for i, (doc, metadata, distance) in enumerate(zip(
                        semantic_results['documents'][0], 
                        semantic_results['metadatas'][0], 
                        semantic_results['distances'][0]
                    )):
                        similarity_score = 1 - distance
                        all_results.append({
                            "text": doc,
                            "score": similarity_score * 0.5,  # Semantic aÄŸÄ±rlÄ±ÄŸÄ±
                            "metadata": metadata,
                            "search_type": "semantic"
                        })
                
                # Keyword sonuÃ§larÄ± ekle
                if keyword_results['documents'] and keyword_results['documents'][0]:
                    for i, (doc, metadata, distance) in enumerate(zip(
                        keyword_results['documents'][0], 
                        keyword_results['metadatas'][0], 
                        keyword_results['distances'][0]
                    )):
                        similarity_score = 1 - distance
                        all_results.append({
                            "text": doc,
                            "score": similarity_score * 0.3,  # Keyword aÄŸÄ±rlÄ±ÄŸÄ±
                            "metadata": metadata,
                            "search_type": "keyword"
                        })
                
                # Tekrar eden sonuÃ§larÄ± birleÅŸtir ve sÄ±rala
                unique_results = {}
                for result in all_results:
                    text_key = result['text'][:100]  # Ä°lk 100 karakteri key olarak kullan
                    if text_key not in unique_results:
                        unique_results[text_key] = result
                    else:
                        # Daha yÃ¼ksek skoru al
                        if result['score'] > unique_results[text_key]['score']:
                            unique_results[text_key] = result
                
                # Skora gÃ¶re sÄ±rala ve top_k kadar al
                sorted_results = sorted(unique_results.values(), key=lambda x: x['score'], reverse=True)
                return [r for r in sorted_results[:top_k] if r['score'] >= score_threshold]
            else:
                # Default semantic search
                results = self.collection.query(
                    query_texts=[query],
                    n_results=top_k,
                    include=["documents", "metadatas", "distances"]
                )

            # SonuÃ§larÄ± filtrele ve dÃ¼zenle
            filtered_results = []
            if results['documents'] and results['documents'][0]:
                for i, (doc, metadata, distance) in enumerate(zip(
                    results['documents'][0], 
                    results['metadatas'][0], 
                    results['distances'][0]
                )):
                    # Distance'Ä± similarity score'a Ã§evir (ChromaDB cosine distance kullanÄ±r)
                    similarity_score = 1 - distance  # Cosine distance'Ä± similarity'e Ã§evir
                    
                    if similarity_score >= score_threshold:
                        filtered_results.append({
                            "text": doc,
                            "score": similarity_score,
                            "metadata": metadata,
                            "search_type": search_type
                        })

            return filtered_results

        except Exception as e:
            st.error(f"Arama hatasÄ±: {e}")
            return []

    def call_openrouter_llm(self, prompt: str, model: str = "microsoft/wizardlm-2-8x22b") -> str:
        """OpenRouter API ile LLM Ã§aÄŸrÄ±sÄ±"""
        if not self.openrouter_api_key:
            return "âŒ OpenRouter API key bulunamadÄ±. LÃ¼tfen .env dosyasÄ±nda OPENROUTER_API_KEY'i ayarlayÄ±n."

        try:
            headers = {
                "Authorization": f"Bearer {self.openrouter_api_key}",
                "Content-Type": "application/json",
                "HTTP-Referer": "https://streamlit.io",
                "X-Title": "RAG PoC System"
            }

            data = {
                "model": model,
                "messages": [
                    {
                        "role": "system",
                        "content": "Sen yardÄ±mcÄ± bir asistansÄ±n. Verilen bilgileri kullanarak doÄŸru, detaylÄ± ve TÃ¼rkÃ§e yanÄ±tlar ver."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                "max_tokens": 500,
                "temperature": 0.7
            }

            response = requests.post(
                "https://openrouter.ai/api/v1/chat/completions",
                headers=headers,
                json=data,
                timeout=30
            )

            if response.status_code == 200:
                result = response.json()
                return result["choices"][0]["message"]["content"]
            else:
                return f"âŒ API HatasÄ±: {response.status_code} - {response.text}"

        except Exception as e:
            return f"âŒ LLM Ã§aÄŸrÄ± hatasÄ±: {e}"

    def generate_rag_response(self, query: str, search_results: List[Dict], model: str) -> str:
        """RAG ile yanÄ±t Ã¼ret"""
        if not search_results:
            return "Ä°lgili bilgi bulunamadÄ±."

        # Context oluÅŸtur
        context_parts = []
        for i, result in enumerate(search_results, 1):
            context_parts.append(f"Kaynak {i}: {result['text']}")

        context = "\n\n".join(context_parts)

        # Prompt oluÅŸtur
        prompt = f"""AÅŸaÄŸÄ±daki kaynaklardaki bilgileri kullanarak soruyu yanÄ±tla:

KAYNAKLAR:
{context}

SORU: {query}

YANIT: YukarÄ±daki kaynaklardaki bilgileri kullanarak soruyu detaylÄ± bir ÅŸekilde yanÄ±tla. Hangi kaynaklarÄ± kullandÄ±ÄŸÄ±nÄ± belirt."""

        return self.call_openrouter_llm(prompt, model)

    def get_collection_stats(self) -> Dict:
        """Collection istatistiklerini al"""
        if not self.collection:
            return {}

        try:
            count = self.collection.count()
            return {
                "total_documents": count,
                "collection_name": self.collection_name
            }
        except Exception as e:
            return {"error": str(e)}


# Ana uygulama
def main():
    # Modern Header
    st.markdown("""
    <div class="main-header">
        <h1>ğŸš€ TrizRAG</h1>
        <p>AI-Powered Document Intelligence & Data Analysis Platform</p>
    </div>
    """, unsafe_allow_html=True)
    
    # RAG sistemi baÅŸlat
    if "rag_system" not in st.session_state:
        st.session_state.rag_system = AdvancedRAGSystem()

    rag_system = st.session_state.rag_system

    # Sidebar - Ayarlar
    with st.sidebar:
        # Logo ve baÅŸlÄ±k
        st.markdown("""
        <div style="text-align: center; padding: 1rem 0;">
            <h2 style="color: #ff4a4a; margin-bottom: 0;">ğŸš€ TrizRAG</h2>
            <p style="color: #666; font-size: 0.9rem; margin: 0;">Control Panel</p>
        </div>
        """, unsafe_allow_html=True)
        
        st.divider()
        
        # Sistem baÅŸlat
        st.header("âš™ï¸ System Setup")
        if st.button("ğŸ”„ Initialize System", type="primary", use_container_width=True):
            with st.spinner("ğŸš€ Initializing TrizRAG..."):
                # Embedding model yÃ¼kle
                embedding_success = rag_system.load_embedding_model()
                # ChromaDB baÅŸlat
                chromadb_success = rag_system.initialize_chromadb()
                # pandasai baÅŸlat
                pandasai_success = rag_system.initialize_pandasai()

                if embedding_success and chromadb_success and pandasai_success:
                    st.success("âœ… TrizRAG successfully initialized!")
                    st.rerun()
                else:
                    st.error("âŒ System initialization failed!")

        st.divider()
        
        # Model seÃ§imi
        st.header("ğŸ¤– AI Model Settings")
        available_models = {
            "ğŸš€ WizardLM-2 8x22B (Free)": "microsoft/wizardlm-2-8x22b",
            "ğŸ¦™ Meta-Llama 3 8B (Free)": "meta-llama/llama-3.2-3b-instruct:free",
            "ğŸŒŸ Google: Gemini 2.5 Pro (Free)": "google/gemini-2.5-pro-exp-03-25",
            "ğŸ” DeepSeek R1 (Free)": "deepseek/deepseek-r1:free"
        }

        selected_model_name = st.selectbox(
            "Select LLM Model:",
            list(available_models.keys())
        )
        selected_model = available_models[selected_model_name]

        # Arama ayarlarÄ±
        st.subheader("ğŸ” Search Configuration")
        
        # Arama tipi seÃ§imi
        search_type = st.selectbox(
            "Search Type:",
            ["semantic", "keyword", "hybrid"],
            format_func=lambda x: {
                "semantic": "ğŸ” Semantic (AI-Powered)",
                "keyword": "ğŸ”¤ Keyword (Text Matching)",
                "hybrid": "ğŸ”„ Hybrid (Best of Both)"
            }[x],
            help="Semantic: AI-powered understanding, Keyword: Exact text matching, Hybrid: Combines both approaches"
        )
        
        search_k = st.slider("Results Count:", 1, 10, 5)
        score_threshold = st.slider("Similarity Threshold:", 0.0, 1.0, 0.5, 0.1)

        st.divider()

        # Sistem durumu
        st.header("ğŸ“Š System Status")

        # BaÄŸlantÄ± durumlarÄ±
        chromadb_status = "ğŸŸ¢ Connected" if rag_system.collection else "ğŸ”´ Disconnected"
        st.markdown(f"""
        <div style="display: flex; align-items: center; margin: 0.5rem 0;">
            <span class="status-indicator {'status-connected' if rag_system.collection else 'status-disconnected'}"></span>
            <span><strong>ChromaDB Cloud:</strong> {chromadb_status}</span>
        </div>
        """, unsafe_allow_html=True)

        embedding_status = "ğŸŸ¢ Loaded" if rag_system.embedding_model else "ğŸ”´ Not Loaded"
        st.markdown(f"""
        <div style="display: flex; align-items: center; margin: 0.5rem 0;">
            <span class="status-indicator {'status-connected' if rag_system.embedding_model else 'status-disconnected'}"></span>
            <span><strong>Embedding Model:</strong> {embedding_status}</span>
        </div>
        """, unsafe_allow_html=True)

        # pandasai durumu
        pandasai_status = "ğŸŸ¢ Configured" if rag_system.pandasai_configured else "ğŸ”´ Not Configured"
        st.markdown(f"""
        <div style="display: flex; align-items: center; margin: 0.5rem 0;">
            <span class="status-indicator {'status-connected' if rag_system.pandasai_configured else 'status-disconnected'}"></span>
            <span><strong>pandasai:</strong> {pandasai_status}</span>
        </div>
        """, unsafe_allow_html=True)

        # ChromaDB Cloud bilgileri


        # Collection istatistikleri
        if rag_system.collection:
            stats = rag_system.get_collection_stats()
            if "total_documents" in stats:
                st.markdown(f"""
                <div class="metric-card">
                    <h3 style="margin: 0; font-size: 1.5rem;">{stats['total_documents']}</h3>
                    <p style="margin: 0; opacity: 0.9;">Total Documents</p>
                </div>
                """, unsafe_allow_html=True)
                

        st.divider()
        
        # Help section
        st.header("â“ Quick Help")
        with st.expander("How to use TrizRAG"):
            st.markdown("""
            **ğŸš€ Getting Started:**
            1. Click "Initialize System" to start
            2. Upload documents in RAG tab
            3. Ask questions about your documents
            4. Upload data in pandasai tab for analysis
            
            **ğŸ’¡ Tips:**
            - Use semantic search for best results
            - Try different AI models for varied responses
            - Upload CSV files for data analysis
            """)

    # Ana iÃ§erik - Sekmeli yapÄ±
    tab1, tab2 = st.tabs(["ğŸ“š Document Intelligence", "ğŸ“Š Data Analytics"])
    
    # Tab 1: Document Intelligence (RAG)
    with tab1:
        st.markdown('<div class="tab-content">', unsafe_allow_html=True)
        
        # Help tooltip
        st.markdown("""
        <div class="help-tooltip">
            <strong>ğŸ’¡ Document Intelligence:</strong> Upload documents and ask AI-powered questions. 
            TrizRAG will search through your documents and provide intelligent answers based on the content.
        </div>
        """, unsafe_allow_html=True)
        
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.header("ğŸ“„ Document Management")
            
            # Modern upload area
            st.markdown("""
            <div class="upload-area">
                <h4>ğŸ“ Upload Documents</h4>
                <p>Drag & drop or click to upload TXT files</p>
            </div>
            """, unsafe_allow_html=True)

            # Dosya yÃ¼kleme
            uploaded_files = st.file_uploader(
                "Choose files:",
                type=['txt'],
                accept_multiple_files=True,
                label_visibility="collapsed"
            )

            # Manuel dÃ¶kÃ¼man giriÅŸi
            st.subheader("âœï¸ Manual Document Input")
            
            # Ã–rnek dÃ¶kÃ¼manlar
            default_docs = """Python, yorumlanabilir, etkileÅŸimli ve nesne yÃ¶nelimli bir programlama dilidir. Guido van Rossum tarafÄ±ndan 1991 yÄ±lÄ±nda geliÅŸtirilmiÅŸtir. Basit sÃ¶zdizimi ve gÃ¼Ã§lÃ¼ kÃ¼tÃ¼phaneleri sayesinde veri bilimi, web geliÅŸtirme, yapay zeka ve otomasyon projelerinde yaygÄ±n olarak kullanÄ±lmaktadÄ±r.

Machine Learning (Makine Ã–ÄŸrenmesi), bilgisayarlarÄ±n verilerden Ã¶ÄŸrenmesini saÄŸlayan yapay zeka dalÄ±dÄ±r. Supervised learning (denetimli Ã¶ÄŸrenme), unsupervised learning (denetimsiz Ã¶ÄŸrenme) ve reinforcement learning (pekiÅŸtirmeli Ã¶ÄŸrenme) olmak Ã¼zere Ã¼Ã§ ana kategoriye ayrÄ±lÄ±r. Scikit-learn, TensorFlow ve PyTorch gibi kÃ¼tÃ¼phaneler ML projelerinde sÄ±kÃ§a kullanÄ±lÄ±r.

RAG (Retrieval-Augmented Generation), bÃ¼yÃ¼k dil modellerinin performansÄ±nÄ± artÄ±rmak iÃ§in kullanÄ±lan bir tekniktir. Ã–nce ilgili bilgiyi bir vektÃ¶r veritabanÄ±ndan alÄ±r, sonra bu bilgiyi context olarak kullanarak LLM ile yanÄ±t Ã¼retir. Bu sayede modelin bilgi gÃ¼ncelliÄŸi ve doÄŸruluÄŸu artar.

Pinecone, yÃ¼ksek performanslÄ± vektÃ¶r veritabanÄ± hizmetidir. Similarity search ve recommendation sistemlerinde kullanÄ±lÄ±r. Serverless mimarisi sayesinde Ã¶lÃ§eklenebilir ve yÃ¶netimi kolaydÄ±r. Ãœcretsiz tier ile baÅŸlayÄ±p, ihtiyaca gÃ¶re Ã¼cretli planlara geÃ§ilebilir.

OpenRouter, farklÄ± AI modellerine tek bir API Ã¼zerinden eriÅŸim saÄŸlayan platformdur. GPT, Claude, Llama gibi Ã§eÅŸitli modelleri destekler. Ãœcretsiz tier ile deneme imkanÄ± sunar ve pay-per-use modeliyle maliyet kontrolÃ¼ saÄŸlar."""

            documents_text = st.text_area(
                "Enter your documents (each paragraph as a separate document):",
                value=default_docs,
                height=300,
                placeholder="Paste your documents here..."
            )

            # DÃ¶kÃ¼man ekleme
            if st.button("ğŸ“š Add Documents", type="primary", use_container_width=True):
                if not rag_system.collection:
                    st.warning("âš ï¸ Please initialize the system first!")
                else:
                    documents = []
                    metadata_list = []

                    # YÃ¼klenen dosyalardan dÃ¶kÃ¼manlarÄ± al
                    if uploaded_files:
                        for file in uploaded_files:
                            content = str(file.read(), "utf-8")
                            documents.append(content)
                            metadata_list.append({
                                "source": file.name,
                                "type": "uploaded_file"
                            })

                    # Manuel girilen dÃ¶kÃ¼manlarÄ± al
                    if documents_text.strip():
                        manual_docs = [doc.strip() for doc in documents_text.split('\n\n') if doc.strip()]
                        documents.extend(manual_docs)
                        for i, doc in enumerate(manual_docs):
                            metadata_list.append({
                                "source": f"manual_input_{i + 1}",
                                "type": "manual_text"
                            })

                    if documents:
                        success = rag_system.upsert_documents(documents, metadata_list)
                        if success:
                            st.success(f"âœ… {len(documents)} documents successfully added!")
                            time.sleep(2)
                            st.rerun()
                        else:
                            st.error("âŒ Document addition failed!")
                    else:
                        st.warning("âš ï¸ No documents to add!")

        with col2:
            st.header("ğŸ’¬ AI-Powered Q&A")

            # Soru giriÅŸi
            query = st.text_input(
                "Ask your question:",
                placeholder="Example: What libraries are used for machine learning in Python?",
                key="rag_query"
            )

            if st.button("ğŸ” Get Intelligent Answer", type="primary", use_container_width=True) and query:
                if not rag_system.collection:
                    st.warning("âš ï¸ Please initialize the system first!")
                elif not rag_system.openrouter_api_key:
                    st.error("âŒ OpenRouter API key not found! Please set OPENROUTER_API_KEY in .env file.")
                else:
                    # Benzer dÃ¶kÃ¼manlarÄ± ara
                    with st.spinner(f"ğŸ” Searching for relevant information... ({search_type})"):
                        search_results = rag_system.search_similar(
                            query,
                            top_k=search_k,
                            score_threshold=score_threshold,
                            search_type=search_type
                        )

                    if search_results:
                        # Arama performans metrikleri
                        avg_score = sum(r['score'] for r in search_results) / len(search_results)
                        st.markdown(f"""
                        <div class="metric-card">
                            <h3 style="margin: 0; font-size: 1.5rem;">{len(search_results)}</h3>
                            <p style="margin: 0; opacity: 0.9;">Results Found</p>
                            <small>Avg Score: {avg_score:.3f}</small>
                        </div>
                        """, unsafe_allow_html=True)
                        
                        # RAG yanÄ±tÄ± Ã¼ret
                        with st.spinner("ğŸ¤– Generating intelligent response..."):
                            response = rag_system.generate_rag_response(
                                query, search_results, selected_model
                            )

                        # SonuÃ§larÄ± gÃ¶ster
                        st.subheader("ğŸ¯ AI Response")
                        st.markdown(f"""
                        <div class="success-message">
                            {response}
                        </div>
                        """, unsafe_allow_html=True)

                        # Kaynak bilgileri
                        with st.expander(f"ğŸ“š Sources Used ({len(search_results)} documents)"):
                            for i, result in enumerate(search_results, 1):
                                # Arama tipi badge'i
                                search_type_badge = {
                                    "semantic": "ğŸ” Semantic",
                                    "keyword": "ğŸ”¤ Keyword", 
                                    "hybrid": "ğŸ”„ Hybrid"
                                }.get(result.get('search_type', 'semantic'), 'ğŸ”')
                                
                                st.write(f"**Source {i}** {search_type_badge} (Score: {result['score']:.3f})")
                                st.write(result['text'])

                                # Metadata bilgileri
                                metadata = result.get('metadata', {})
                                if metadata:
                                    st.caption(f"ğŸ“ Source: {metadata.get('source', 'Unknown')} | "
                                               f"Type: {metadata.get('type', 'Unknown')}")
                                st.divider()
                    else:
                        st.warning("âš ï¸ No relevant information found. Try lowering the similarity threshold.")

        st.markdown('</div>', unsafe_allow_html=True)

    # Tab 2: Data Analytics (pandasai)
    with tab2:
        st.markdown('<div class="tab-content">', unsafe_allow_html=True)
        
        # Help tooltip
        st.markdown("""
        <div class="help-tooltip">
            <strong>ğŸ’¡ Data Analytics:</strong> Upload CSV files or enter data manually, then ask AI-powered questions about your data. 
            TrizRAG will analyze your data and provide intelligent insights.
        </div>
        """, unsafe_allow_html=True)
        
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.header("ğŸ“ Data Upload")
            
            # Modern upload area
            st.markdown("""
            <div class="upload-area">
                <h4>ğŸ“Š Upload Data</h4>
                <p>Drag & drop or click to upload CSV files</p>
            </div>
            """, unsafe_allow_html=True)
            
            # CSV dosya yÃ¼kleme
            csv_file = st.file_uploader(
                "Choose CSV file:",
                type=['csv'],
                key="csv_uploader",
                label_visibility="collapsed"
            )

            if csv_file:
                try:
                    df = pd.read_csv(csv_file)
                    df_name = csv_file.name.replace('.csv', '')
                    
                    if st.button(f"ğŸ“Š Add '{df_name}' Dataset", type="primary", use_container_width=True):
                        success = rag_system.add_dataframe(df_name, df)
                        if success:
                            st.success(f"âœ… '{df_name}' dataset successfully added!")
                            st.rerun()
                        else:
                            st.error("âŒ Dataset addition failed!")
                    
                    # DataFrame Ã¶nizleme
                    st.subheader("ğŸ‘€ Data Preview")
                    st.markdown(f"""
                    <div class="metric-card">
                        <h3 style="margin: 0; font-size: 1.5rem;">{df.shape[0]} Ã— {df.shape[1]}</h3>
                        <p style="margin: 0; opacity: 0.9;">Rows Ã— Columns</p>
                    </div>
                    """, unsafe_allow_html=True)
                    st.dataframe(df.head(10))
                    
                except Exception as e:
                    st.error(f"CSV reading error: {e}")

            # Manuel veri giriÅŸi
            st.subheader("âœï¸ Manual Data Input")
            
            # Ã–rnek veri
            sample_data = """name,age,city,salary
Ahmet,25,Ä°stanbul,5000
AyÅŸe,30,Ankara,6000
Mehmet,35,Ä°zmir,7000
Fatma,28,Bursa,5500
Ali,32,Antalya,6500"""
            
            manual_data = st.text_area(
                "Enter data in CSV format:",
                value=sample_data,
                height=150,
                placeholder="Enter your data here..."
            )
            
            if st.button("ğŸ“Š Convert to Dataset", type="primary", use_container_width=True):
                try:
                    from io import StringIO
                    df = pd.read_csv(StringIO(manual_data))
                    df_name = "manual_data"
                    
                    success = rag_system.add_dataframe(df_name, df)
                    if success:
                        st.success(f"âœ… '{df_name}' dataset successfully added!")
                        st.rerun()
                    else:
                        st.error("âŒ Dataset addition failed!")
                        
                except Exception as e:
                    st.error(f"Data reading error: {e}")

        with col2:
            st.header("ğŸ—‚ï¸ Available Datasets")
            
            if rag_system.dataframes:
                for df_name in rag_system.list_dataframes():
                    pai_df = rag_system.get_dataframe(df_name)
                    # pandasai DataFrame'den orijinal pandas DataFrame'i al
                    df = pai_df._df if hasattr(pai_df, '_df') else pai_df
                    
                    with st.expander(f"ğŸ“Š {df_name} ({df.shape[0]}Ã—{df.shape[1]})"):
                        st.dataframe(df.head(5))
                        
                        # DataFrame analizi
                        if st.button(f"ğŸ” Analyze {df_name}", key=f"analyze_{df_name}"):
                            analysis = rag_system.analyze_dataframe(df_name)
                            if "error" not in analysis:
                                st.write("**ğŸ“ˆ Data Analysis:**")
                                st.write(f"**Shape:** {analysis['shape']}")
                                st.write(f"**Columns:** {', '.join(analysis['columns'])}")
                                st.write(f"**Numeric Columns:** {', '.join(analysis['numeric_columns'])}")
                                st.write(f"**Categorical Columns:** {', '.join(analysis['categorical_columns'])}")
                                
                                # Eksik veri analizi
                                missing_data = {k: v for k, v in analysis['missing_values'].items() if v > 0}
                                if missing_data:
                                    st.write(f"**âš ï¸ Missing Values:** {missing_data}")
                            else:
                                st.error(analysis['error'])
            else:
                st.info("â„¹ï¸ No datasets uploaded yet. Upload data from the left side!")

        # pandasai Sohbet - Tam geniÅŸlik
        if rag_system.pandasai_configured and rag_system.dataframes:
            st.divider()
            st.header("ğŸ’¬ AI Data Analysis")
            
            col3, col4 = st.columns([1, 1])
            
            with col3:
                # DataFrame seÃ§imi
                selected_df = st.selectbox(
                    "Select dataset:",
                    rag_system.list_dataframes()
                )
                
                # Sohbet sorusu
                chat_query = st.text_input(
                    "Ask about your data:",
                    placeholder="Example: What is the average age? Who has the highest salary?",
                    key="pandasai_chat"
                )
                
                if st.button("ğŸ¤– Get AI Analysis", type="primary", use_container_width=True) and chat_query:
                    with st.spinner("ğŸ¤– AI is analyzing your data..."):
                        response = rag_system.chat_with_dataframe(selected_df, chat_query)
                    
                    st.subheader("ğŸ¯ AI Analysis")
                    st.markdown(f"""
                    <div class="success-message">
                        {response}
                    </div>
                    """, unsafe_allow_html=True)
            
            with col4:
                st.markdown("""
                <div class="help-tooltip">
                    <strong>ğŸ’¡ AI Data Analysis Tips:</strong>
                    
                    **ğŸ“Š Basic Questions:**
                    â€¢ "What is the average age?"
                    â€¢ "Who has the highest salary?"
                    
                    **ğŸ” Advanced Analysis:**
                    â€¢ "Show me salary distribution by city"
                    â€¢ "What's the correlation between age and salary?"
                    â€¢ "Create a summary of the data"
                    
                    **ğŸ“ˆ Visualization Requests:**
                    â€¢ "Plot age vs salary"
                    â€¢ "Show city distribution"
                </div>
                """, unsafe_allow_html=True)
        
        elif not rag_system.pandasai_configured:
            st.warning("âš ï¸ pandasai not configured yet!")
        elif not rag_system.dataframes:
            st.info("â„¹ï¸ Please upload a dataset first!")

        st.markdown('</div>', unsafe_allow_html=True)

    # Alt bilgi
    st.markdown("---")
    
    # Modern footer
    col1, col2, col3 = st.columns([1, 2, 1])
    
    with col1:
        st.markdown("""
        <div style="text-align: center;">
            <h3 style="color: #ff4a4a; margin: 0;">ğŸš€ TrizRAG</h3>
            <p style="color: #666; font-size: 0.9rem; margin: 0;">AI-Powered Intelligence</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown("""
        <div style="text-align: center; padding: 1rem;">
            <p style="color: #666; margin: 0;">
                <strong>Powered by:</strong> ChromaDB Cloud â€¢ OpenRouter LLM â€¢ pandasai
            </p>
            <p style="color: #999; font-size: 0.8rem; margin: 0.5rem 0 0 0;">
                Transform your documents and data into intelligent insights
            </p>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown("""
        <div style="text-align: center;">
            <p style="color: #666; font-size: 0.9rem; margin: 0;">Version 1.0</p>
            <p style="color: #999; font-size: 0.8rem; margin: 0;">Â© 2025 TrizRAG</p>
        </div>
        """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()