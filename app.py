import streamlit as st
import chromadb
from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction
from sentence_transformers import SentenceTransformer
import numpy as np
import hashlib
import time
from typing import List, Dict
import requests
import os
from datetime import datetime
from dotenv import load_dotenv
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import pandasai as pai
from pandasai_litellm.litellm import LiteLLM


# .env dosyasƒ±nƒ± y√ºkle
load_dotenv()

# Sayfa konfig√ºrasyonu
st.set_page_config(
    page_title="TrizRAG - AI-Powered Document Intelligence",
    page_icon="üöÄ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS stilleri
st.markdown("""
<style>
    .main-header {
        background: #ff4a4a;
        padding: 2rem;
        border-radius: 15px;
        margin-bottom: 2rem;
        text-align: center;
        color: white;
    }
    
    .main-header h1 {
        font-size: 3rem;
        font-weight: 700;
        margin-bottom: 0.5rem;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
    }
    
    .main-header p {
        font-size: 1.2rem;
        opacity: 0.9;
        margin-bottom: 0;
    }
    
    .feature-card {
        background: #ff4a4a;
        padding: 1.5rem;
        border-radius: 10px;
        border: 1px solid #e0e0e0;
        box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        margin-bottom: 1rem;
    }
    
    .status-indicator {
        display: inline-block;
        width: 12px;
        height: 12px;
        border-radius: 50%;
        margin-right: 8px;
    }
    
    .status-connected { background-color: #4CAF50; }
    .status-disconnected { background-color: #f44336; }
    .status-loading { background-color: #ff9800; }
    
    .metric-card {
        background: #ff4a4a;
        color: white;
        padding: 1rem;
        border-radius: 10px;
        text-align: center;
        margin: 0.5rem 0;
    }
    
    .help-tooltip {
        
        border-left: 4px solid #ff4a4a;
        padding: 1rem;
        margin: 1rem 0;
        border-radius: 5px;
    }
    
    .success-message {
        background-color: #d4edda;
        border: 1px solid #c3e6cb;
        color: #155724;
        padding: 1rem;
        border-radius: 5px;
        margin: 1rem 0;
    }
    
    .error-message {
        background-color: #f8d7da;
        border: 1px solid #f5c6cb;
        color: #721c24;
        padding: 1rem;
        border-radius: 5px;
        margin: 1rem 0;
    }
    
    .warning-message {
        background-color: #fff3cd;
        border: 1px solid #ffeaa7;
        color: #856404;
        padding: 1rem;
        border-radius: 5px;
        margin: 1rem 0;
    }
    
    .tab-content {
        padding: 1rem 0;
    }
    
    .upload-area {
        border: 1px solid;
        border-radius: 10px;
        padding: 2rem;
        text-align: center;
        transition: all 0.3s ease;
    }
    
    .upload-area:hover {
        border-color: #ff4a4a;
        background-color: #ff4a4a;
        transition: all 0.5s ease;
    }
    }
</style>
""", unsafe_allow_html=True)


class AdvancedRAGSystem:
    def __init__(self):
        self.embedding_model = None
        self.client = None
        self.collection = None
        self.collection_name = "rag-poc-collection"
        # OpenRouter API key'i .env'den otomatik al
        self.openrouter_api_key = os.getenv("OPENROUTER_API_KEY")
        self.dimension = 1024  # all-MiniLM-L6-v2 embedding boyutu
        self.chroma_api_key = os.getenv("CHROMA_API_KEY")
        self.chroma_tenant = os.getenv("CHROMA_TENANT")
        self.chroma_database = os.getenv("CHROMA_DATABASE")
        

    def initialize_chromadb(self):
        """ChromaDB Cloud'u ba≈ülat"""
        try:
            # ChromaDB Cloud client'ƒ± ba≈ülat
            self.client = chromadb.HttpClient(
                ssl=True,
                host='api.trychroma.com',
                tenant=self.chroma_tenant,
                database=self.chroma_database,
                headers={
                    'x-chroma-token': self.chroma_api_key
                }
            )
            
            # Embedding function olu≈ütur
            embedding_function = SentenceTransformerEmbeddingFunction(
                model_name='intfloat/multilingual-e5-large'
            )
            
            # Collection'ƒ± olu≈ütur veya al
            try:
                self.collection = self.client.get_collection(
                    name=self.collection_name,
                    embedding_function=embedding_function
                )
            except:
                self.collection = self.client.create_collection(
                    name=self.collection_name,
                    embedding_function=embedding_function
                )
            
            return True

        except Exception as e:
            st.error(f"ChromaDB Cloud baƒülantƒ± hatasƒ±: {e}")
            return False

    

    @st.cache_resource
    def load_embedding_model(_self):
        """Embedding modelini y√ºkle"""
        try:
            _self.embedding_model = SentenceTransformer('intfloat/multilingual-e5-large')
            return True
        except Exception as e:
            st.error(f"Embedding model y√ºkleme hatasƒ±: {e}")
            return False

    def chunk_text(self, text: str, chunk_size: int = 500, overlap: int = 50) -> List[str]:
        """Metni par√ßalara b√∂l"""
        chunks = []
        start = 0
        text_length = len(text)

        while start < text_length:
            end = start + chunk_size
            if end > text_length:
                end = text_length

            chunk = text[start:end]
            chunks.append(chunk.strip())

            if end == text_length:
                break

            start = end - overlap

        return [chunk for chunk in chunks if len(chunk.strip()) > 10]

    def generate_id(self, text: str) -> str:
        """Metin i√ßin benzersiz ID √ºret"""
        return hashlib.md5(text.encode()).hexdigest()

    def upsert_documents(self, documents: List[str], metadata_list: List[Dict] = None) -> bool:
        """D√∂k√ºmanlarƒ± ChromaDB'ye ekle"""
        if not self.collection:
            return False

        try:
            all_ids = []
            all_documents = []
            all_metadatas = []

            with st.spinner("D√∂k√ºmanlar i≈üleniyor ve vekt√∂rle≈ütiriliyor..."):
                for i, doc in enumerate(documents):
                    # Metni par√ßalara b√∂l
                    chunks = self.chunk_text(doc)

                    for j, chunk in enumerate(chunks):
                        # ID olu≈ütur
                        chunk_id = f"doc_{i}_chunk_{j}_{self.generate_id(chunk)[:8]}"

                        # Metadata hazƒ±rla
                        metadata = {
                            "doc_id": i,
                            "chunk_id": j,
                            "timestamp": datetime.now().isoformat(),
                            "length": len(chunk)
                        }

                        if metadata_list and i < len(metadata_list):
                            metadata.update(metadata_list[i])

                        all_ids.append(chunk_id)
                        all_documents.append(chunk)
                        all_metadatas.append(metadata)

            # ChromaDB'ye ekle
            self.collection.add(
                ids=all_ids,
                documents=all_documents,
                metadatas=all_metadatas
            )

            return True

        except Exception as e:
            st.error(f"D√∂k√ºman ekleme hatasƒ±: {e}")
            return False

    def search_similar(self, query: str, top_k: int = 5, score_threshold: float = 0.5, search_type: str = "semantic") -> List[Dict]:
        """Benzer d√∂k√ºmanlarƒ± ara"""
        if not self.collection:
            return []

        try:
            if search_type == "semantic":
                # Semantic search - embedding tabanlƒ±
                results = self.collection.query(
                    query_texts=[query],
                    n_results=top_k,
                    include=["documents", "metadatas", "distances"]
                )
            elif search_type == "keyword":
                # Keyword search - where clause ile
                results = self.collection.query(
                    query_texts=[query],
                    n_results=top_k,
                    where={"$or": [{"text": {"$contains": word}} for word in query.lower().split() if len(word) > 2]},
                    include=["documents", "metadatas", "distances"]
                )
            elif search_type == "hybrid":
                # Hybrid search - hem semantic hem keyword
                semantic_results = self.collection.query(
                    query_texts=[query],
                    n_results=top_k * 2,  # Daha fazla sonu√ß al
                    include=["documents", "metadatas", "distances"]
                )
                
                keyword_results = self.collection.query(
                    query_texts=[query],
                    n_results=top_k * 2,
                    where={"$or": [{"text": {"$contains": word}} for word in query.lower().split() if len(word) > 2]},
                    include=["documents", "metadatas", "distances"]
                )
                
                # Sonu√ßlarƒ± birle≈ütir ve sƒ±rala
                all_results = []
                
                # Semantic sonu√ßlarƒ± ekle
                if semantic_results['documents'] and semantic_results['documents'][0]:
                    for i, (doc, metadata, distance) in enumerate(zip(
                        semantic_results['documents'][0], 
                        semantic_results['metadatas'][0], 
                        semantic_results['distances'][0]
                    )):
                        similarity_score = max(0.0, 1 - distance)
                        all_results.append({
                            "text": doc,
                            "score": similarity_score * 0.5,  # Semantic aƒüƒ±rlƒ±ƒüƒ±
                            "metadata": metadata,
                            "search_type": "semantic"
                        })
                
                # Keyword sonu√ßlarƒ± ekle
                if keyword_results['documents'] and keyword_results['documents'][0]:
                    for i, (doc, metadata, distance) in enumerate(zip(
                        keyword_results['documents'][0], 
                        keyword_results['metadatas'][0], 
                        keyword_results['distances'][0]
                    )):
                        similarity_score = 1 - distance
                        all_results.append({
                            "text": doc,
                            "score": similarity_score * 0.3,  # Keyword aƒüƒ±rlƒ±ƒüƒ±
                            "metadata": metadata,
                            "search_type": "keyword"
                        })
                
                # Tekrar eden sonu√ßlarƒ± birle≈ütir ve sƒ±rala
                unique_results = {}
                for result in all_results:
                    text_key = result['text'][:100]  # ƒ∞lk 100 karakteri key olarak kullan
                    if text_key not in unique_results:
                        unique_results[text_key] = result
                    else:
                        # Daha y√ºksek skoru al
                        if result['score'] > unique_results[text_key]['score']:
                            unique_results[text_key] = result
                
                # Skora g√∂re sƒ±rala ve top_k kadar al
                sorted_results = sorted(unique_results.values(), key=lambda x: x['score'], reverse=True)
                return [r for r in sorted_results[:top_k] if r['score'] >= score_threshold]
            else:
                # Default semantic search
                results = self.collection.query(
                    query_texts=[query],
                    n_results=top_k,
                    include=["documents", "metadatas", "distances"]
                )

            # Sonu√ßlarƒ± filtrele ve d√ºzenle
            filtered_results = []
            if results['documents'] and results['documents'][0]:
                for i, (doc, metadata, distance) in enumerate(zip(
                    results['documents'][0], 
                    results['metadatas'][0], 
                    results['distances'][0]
                )):
                    # Distance'ƒ± similarity score'a √ßevir (ChromaDB cosine distance kullanƒ±r)
                    similarity_score = 1 - distance  # Cosine distance'ƒ± similarity'e √ßevir
                    
                    if similarity_score >= score_threshold:
                        filtered_results.append({
                            "text": doc,
                            "score": similarity_score,
                            "metadata": metadata,
                            "search_type": search_type
                        })

            return filtered_results

        except Exception as e:
            st.error(f"Arama hatasƒ±: {e}")
            return []

    def call_openrouter_llm(self, prompt: str, model: str = "microsoft/wizardlm-2-8x22b") -> str:
        """OpenRouter API ile LLM √ßaƒürƒ±sƒ±"""
        if not self.openrouter_api_key:
            return "‚ùå OpenRouter API key bulunamadƒ±. L√ºtfen .env dosyasƒ±nda OPENROUTER_API_KEY'i ayarlayƒ±n."

        try:
            headers = {
                "Authorization": f"Bearer {self.openrouter_api_key}",
                "Content-Type": "application/json",
                "HTTP-Referer": "https://streamlit.io",
                "X-Title": "RAG PoC System"
            }

            data = {
                "model": model,
                "messages": [
                    {
                        "role": "system",
                        "content": "Sen yardƒ±mcƒ± bir asistansƒ±n. Verilen bilgileri kullanarak doƒüru, detaylƒ± ve T√ºrk√ße yanƒ±tlar ver."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                "max_tokens": 500,
                "temperature": 0.7
            }

            response = requests.post(
                "https://openrouter.ai/api/v1/chat/completions",
                headers=headers,
                json=data,
                timeout=30
            )

            if response.status_code == 200:
                result = response.json()
                return result["choices"][0]["message"]["content"]
            else:
                return f"‚ùå API Hatasƒ±: {response.status_code} - {response.text}"

        except Exception as e:
            return f"‚ùå LLM √ßaƒürƒ± hatasƒ±: {e}"

    def generate_rag_response(self, query: str, search_results: List[Dict], model: str) -> str:
        """RAG ile yanƒ±t √ºret"""
        if not search_results:
            return "ƒ∞lgili bilgi bulunamadƒ±."

        # Context olu≈ütur
        context_parts = []
        for i, result in enumerate(search_results, 1):
            context_parts.append(f"Kaynak {i}: {result['text']}")

        context = "\n\n".join(context_parts)

        # Prompt olu≈ütur
        prompt = f"""A≈üaƒüƒ±daki kaynaklardaki bilgileri kullanarak soruyu yanƒ±tla:

KAYNAKLAR:
{context}

SORU: {query}

YANIT: Yukarƒ±daki kaynaklardaki bilgileri kullanarak soruyu detaylƒ± bir ≈üekilde yanƒ±tla. Hangi kaynaklarƒ± kullandƒ±ƒüƒ±nƒ± belirt."""

        return self.call_openrouter_llm(prompt, model)

    def get_collection_stats(self) -> Dict:
        """Collection istatistiklerini al"""
        if not self.collection:
            return {}

        try:
            count = self.collection.count()
            return {
                "total_documents": count,
                "collection_name": self.collection_name
            }
        except Exception as e:
            return {"error": str(e)}

    def analyze_data_with_pandasai(self, df: pd.DataFrame, query: str) -> Dict:
        """PandasAI ile veri analizi yap"""
        try:
            openrouter_api_key = os.getenv("OPENROUTER_API_KEY")
            if not openrouter_api_key:
                return {
                    "success": False,
                    "error": "OpenRouter API key bulunamadƒ±. L√ºtfen .env dosyasƒ±nda OPENROUTER_API_KEY'i ayarlayƒ±n."
                }

            # OpenRouter API key'i environment variable olarak ayarla
            os.environ["OPENROUTER_API_KEY"] = openrouter_api_key
            
            # LiteLLM ile LLM olu≈ütur
            llm = LiteLLM(model="openrouter/mistralai/mistral-small-3.1-24b-instruct:free")
            
            # pandasai konfig√ºrasyonu
            pai.config.set({
                "llm": llm
            })

            # pandas DataFrame'i pandasai DataFrame'e √ßevir
            pai_df = pai.DataFrame(df)

            # Veri analizi yap - pai.chat kullan
            with st.spinner("ü§ñ AI analyzing your data..."):
                response = pai_df.chat(query)

            return {
                "success": True,    
                "response": response,
                "dataframe_info": {
                    "shape": df.shape,
                    "columns": df.columns.tolist(),
                    "dtypes": df.dtypes.to_dict(),
                    "missing_values": df.isnull().sum().to_dict()
                }
            }

        except Exception as e:
            return {
                "success": False,
                "error": f"Veri analizi hatasƒ±: {str(e)}"
            }

    def create_visualization(self, df: pd.DataFrame, chart_type: str, x_col: str, y_col: str, 
                           title: str = "", color_col: str = None) -> go.Figure:
        """Veri g√∂rselle≈ütirme olu≈ütur"""
        try:
            if chart_type == "bar":
                fig = px.bar(df, x=x_col, y=y_col, title=title, color=color_col)
            elif chart_type == "line":
                fig = px.line(df, x=x_col, y=y_col, title=title, color=color_col)
            elif chart_type == "scatter":
                fig = px.scatter(df, x=x_col, y=y_col, title=title, color=color_col)
            elif chart_type == "histogram":
                fig = px.histogram(df, x=x_col, title=title, color=color_col)
            elif chart_type == "box":
                fig = px.box(df, x=x_col, y=y_col, title=title, color=color_col)
            elif chart_type == "pie":
                fig = px.pie(df, values=y_col, names=x_col, title=title)
            else:
                fig = px.bar(df, x=x_col, y=y_col, title=title)

            fig.update_layout(
                template="plotly_white",
                title_x=0.5,
                height=500
            )
            return fig

        except Exception as e:
            st.error(f"G√∂rselle≈ütirme hatasƒ±: {e}")
            return None

    def get_data_summary(self, df: pd.DataFrame) -> Dict:
        """Veri √∂zeti olu≈ütur"""
        try:
            summary = {
                "shape": df.shape,
                "columns": df.columns.tolist(),
                "dtypes": df.dtypes.to_dict(),
                "missing_values": df.isnull().sum().to_dict(),
                "numeric_columns": df.select_dtypes(include=[np.number]).columns.tolist(),
                "categorical_columns": df.select_dtypes(include=['object']).columns.tolist(),
                "memory_usage": df.memory_usage(deep=True).sum() / 1024 / 1024  # MB
            }

            # Sayƒ±sal s√ºtunlar i√ßin istatistikler
            if summary["numeric_columns"]:
                summary["numeric_stats"] = df[summary["numeric_columns"]].describe().to_dict()

            # Kategorik s√ºtunlar i√ßin unique deƒüer sayƒ±larƒ±
            if summary["categorical_columns"]:
                summary["categorical_stats"] = {
                    col: df[col].nunique() for col in summary["categorical_columns"]
                }

            return summary

        except Exception as e:
            return {"error": f"√ñzet olu≈üturma hatasƒ±: {str(e)}"}

    def suggest_visualizations(self, df: pd.DataFrame) -> List[Dict]:
        """Veri tipine g√∂re g√∂rselle≈ütirme √∂nerileri"""
        suggestions = []
        
        try:
            numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
            categorical_cols = df.select_dtypes(include=['object']).columns.tolist()
            
            # Sayƒ±sal s√ºtunlar i√ßin √∂neriler
            if len(numeric_cols) >= 2:
                suggestions.append({
                    "type": "scatter",
                    "title": f"{numeric_cols[0]} vs {numeric_cols[1]} ƒ∞li≈ükisi",
                    "x_col": numeric_cols[0],
                    "y_col": numeric_cols[1],
                    "description": "ƒ∞ki sayƒ±sal deƒüi≈üken arasƒ±ndaki ili≈ükiyi g√∂sterir"
                })
                
                suggestions.append({
                    "type": "line",
                    "title": f"{numeric_cols[0]} Trendi",
                    "x_col": df.index.name if df.index.name else "Index",
                    "y_col": numeric_cols[0],
                    "description": "Zaman serisi analizi i√ßin uygun"
                })
            
            # Kategorik s√ºtunlar i√ßin √∂neriler
            if categorical_cols and numeric_cols:
                suggestions.append({
                    "type": "bar",
                    "title": f"{categorical_cols[0]} Kategorilerine G√∂re {numeric_cols[0]}",
                    "x_col": categorical_cols[0],
                    "y_col": numeric_cols[0],
                    "description": "Kategorik deƒüi≈ükenlere g√∂re sayƒ±sal deƒüerlerin kar≈üƒ±la≈ütƒ±rmasƒ±"
                })
            
            # Histogram √∂nerileri
            if numeric_cols:
                suggestions.append({
                    "type": "histogram",
                    "title": f"{numeric_cols[0]} Daƒüƒ±lƒ±mƒ±",
                    "x_col": numeric_cols[0],
                    "description": "Sayƒ±sal deƒüi≈ükenin daƒüƒ±lƒ±mƒ±nƒ± g√∂sterir"
                })
            
            # Box plot √∂nerileri
            if len(numeric_cols) >= 1 and len(categorical_cols) >= 1:
                suggestions.append({
                    "type": "box",
                    "title": f"{categorical_cols[0]} Kategorilerine G√∂re {numeric_cols[0]} Daƒüƒ±lƒ±mƒ±",
                    "x_col": categorical_cols[0],
                    "y_col": numeric_cols[0],
                    "description": "Kategorilere g√∂re sayƒ±sal deƒüi≈ükenin daƒüƒ±lƒ±mƒ±nƒ± g√∂sterir"
                })
                
        except Exception as e:
            st.error(f"√ñneri olu≈üturma hatasƒ±: {e}")
            
        return suggestions


# Ana uygulama
def main():
    # Modern Header
    st.markdown("""
    <div class="main-header">
        <h1>üöÄ TrizRAG</h1>
        <p>AI-Powered Document Intelligence & Data Analysis Platform</p>
    </div>
    """, unsafe_allow_html=True)
    
    # RAG sistemi ba≈ülat
    if "rag_system" not in st.session_state:
        st.session_state.rag_system = AdvancedRAGSystem()

    rag_system = st.session_state.rag_system

    # Sidebar - Ayarlar
    with st.sidebar:
        # Logo ve ba≈ülƒ±k
        st.markdown("""
        <div style="text-align: center; padding: 1rem 0;">
            <h2 style="color: #ff4a4a; margin-bottom: 0;">üöÄ TrizRAG</h2>
            <p style="color: #666; font-size: 0.9rem; margin: 0;">Control Panel</p>
        </div>
        """, unsafe_allow_html=True)
        
        st.divider()
        
        # Sistem ba≈ülat
        st.header("‚öôÔ∏è System Setup")
        if st.button("üîÑ Initialize System", type="primary", use_container_width=True):
            with st.spinner("üöÄ Initializing TrizRAG..."):
                # Embedding model y√ºkle
                embedding_success = rag_system.load_embedding_model()
                # ChromaDB ba≈ülat
                chromadb_success = rag_system.initialize_chromadb()
                

                if embedding_success and chromadb_success:
                    st.success("‚úÖ TrizRAG successfully initialized!")
                    st.rerun()
                else:
                    st.error("‚ùå System initialization failed!")

        st.divider()
        
        # Model se√ßimi
        st.header("ü§ñ AI Model Settings")
        available_models = {
            "üöÄ WizardLM-2 8x22B (Free)": "microsoft/wizardlm-2-8x22b",
            "ü¶ô Meta-Llama 3 8B (Free)": "meta-llama/llama-3.2-3b-instruct:free",
            "üåü Google: Gemini 2.5 Pro (Free)": "google/gemini-2.5-pro-exp-03-25",
            "üîç DeepSeek R1 (Free)": "deepseek/deepseek-r1:free"
        }

        selected_model_name = st.selectbox(
            "Select LLM Model:",
            list(available_models.keys())
        )
        selected_model = available_models[selected_model_name]

        # Arama ayarlarƒ±
        st.subheader("üîç Search Configuration")
        
        # Arama tipi se√ßimi
        search_type = st.selectbox(
            "Search Type:",
            ["semantic", "keyword", "hybrid"],
            format_func=lambda x: {
                "semantic": "üîç Semantic (AI-Powered)",
                "keyword": "üî§ Keyword (Text Matching)",
                "hybrid": "üîÑ Hybrid (Best of Both)"
            }[x],
            help="Semantic: AI-powered understanding, Keyword: Exact text matching, Hybrid: Combines both approaches"
        )
        
        search_k = st.slider("Results Count:", 1, 10, 5)
        score_threshold = st.slider("Similarity Threshold:", 0.0, 1.0, 0.5, 0.1)

        st.divider()

        # Sistem durumu
        st.header("üìä System Status")

        # Baƒülantƒ± durumlarƒ±
        chromadb_status = "üü¢ Connected" if rag_system.collection else "üî¥ Disconnected"
        st.markdown(f"""
        <div style="display: flex; align-items: center; margin: 0.5rem 0;">
            <span class="status-indicator {'status-connected' if rag_system.collection else 'status-disconnected'}"></span>
            <span><strong>ChromaDB Cloud:</strong> {chromadb_status}</span>
        </div>
        """, unsafe_allow_html=True)

        embedding_status = "üü¢ Loaded" if rag_system.embedding_model else "üî¥ Not Loaded"
        st.markdown(f"""
        <div style="display: flex; align-items: center; margin: 0.5rem 0;">
            <span class="status-indicator {'status-connected' if rag_system.embedding_model else 'status-disconnected'}"></span>
            <span><strong>Embedding Model:</strong> {embedding_status}</span>
        </div>
        """, unsafe_allow_html=True)

        

        # ChromaDB Cloud bilgileri


        # Collection istatistikleri
        if rag_system.collection:
            stats = rag_system.get_collection_stats()
            if "total_documents" in stats:
                st.markdown(f"""
                <div class="metric-card">
                    <h3 style="margin: 0; font-size: 1.5rem;">{stats['total_documents']}</h3>
                    <p style="margin: 0; opacity: 0.9;">Total Documents</p>
                </div>
                """, unsafe_allow_html=True)
                

        st.divider()
        
        # Help section
        st.header("‚ùì Quick Help")
        with st.expander("How to use TrizRAG"):
            st.markdown("""
            **üöÄ Getting Started:**
            1. Click "Initialize System" to start
            2. Upload documents in RAG tab
            3. Ask questions about your documents
            
            
            **üí° Tips:**
            - Use semantic search for best results
            - Try different AI models for varied responses
            - Upload CSV files for data analysis
            """)

    # Ana i√ßerik - Sekmeli yapƒ±
    tab1, tab2 = st.tabs(["üìö Document Intelligence", "üìä Data Analytics"])
    
    # Tab 1: Document Intelligence (RAG)
    with tab1:
        st.markdown('<div class="tab-content">', unsafe_allow_html=True)
        
        # Help tooltip
        st.markdown("""
        <div class="help-tooltip">
            <strong>üí° Document Intelligence:</strong> Upload documents and ask AI-powered questions. 
            TrizRAG will search through your documents and provide intelligent answers based on the content.
        </div>
        """, unsafe_allow_html=True)
        
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.header("üìÑ Document Management")
            
            # Modern upload area
            st.markdown("""
            <div class="upload-area">
                <h4>üìÅ Upload Documents</h4>
                <p>Drag & drop or click to upload TXT files</p>
            </div>
            """, unsafe_allow_html=True)

            # Dosya y√ºkleme
            uploaded_files = st.file_uploader(
                "Choose files:",
                type=['txt'],
                accept_multiple_files=True,
                label_visibility="collapsed"
            )

            # Manuel d√∂k√ºman giri≈üi
            st.subheader("‚úçÔ∏è Manual Document Input")
            
            # √ñrnek d√∂k√ºmanlar
            default_docs = """Python, yorumlanabilir, etkile≈üimli ve nesne y√∂nelimli bir programlama dilidir. Guido van Rossum tarafƒ±ndan 1991 yƒ±lƒ±nda geli≈ütirilmi≈ütir. Basit s√∂zdizimi ve g√º√ßl√º k√ºt√ºphaneleri sayesinde veri bilimi, web geli≈ütirme, yapay zeka ve otomasyon projelerinde yaygƒ±n olarak kullanƒ±lmaktadƒ±r.

Machine Learning (Makine √ñƒürenmesi), bilgisayarlarƒ±n verilerden √∂ƒürenmesini saƒülayan yapay zeka dalƒ±dƒ±r. Supervised learning (denetimli √∂ƒürenme), unsupervised learning (denetimsiz √∂ƒürenme) ve reinforcement learning (peki≈ütirmeli √∂ƒürenme) olmak √ºzere √º√ß ana kategoriye ayrƒ±lƒ±r. Scikit-learn, TensorFlow ve PyTorch gibi k√ºt√ºphaneler ML projelerinde sƒ±k√ßa kullanƒ±lƒ±r.

RAG (Retrieval-Augmented Generation), b√ºy√ºk dil modellerinin performansƒ±nƒ± artƒ±rmak i√ßin kullanƒ±lan bir tekniktir. √ñnce ilgili bilgiyi bir vekt√∂r veritabanƒ±ndan alƒ±r, sonra bu bilgiyi context olarak kullanarak LLM ile yanƒ±t √ºretir. Bu sayede modelin bilgi g√ºncelliƒüi ve doƒüruluƒüu artar.

Pinecone, y√ºksek performanslƒ± vekt√∂r veritabanƒ± hizmetidir. Similarity search ve recommendation sistemlerinde kullanƒ±lƒ±r. Serverless mimarisi sayesinde √∂l√ßeklenebilir ve y√∂netimi kolaydƒ±r. √úcretsiz tier ile ba≈ülayƒ±p, ihtiyaca g√∂re √ºcretli planlara ge√ßilebilir.

OpenRouter, farklƒ± AI modellerine tek bir API √ºzerinden eri≈üim saƒülayan platformdur. GPT, Claude, Llama gibi √ße≈üitli modelleri destekler. √úcretsiz tier ile deneme imkanƒ± sunar ve pay-per-use modeliyle maliyet kontrol√º saƒülar."""

            documents_text = st.text_area(
                "Enter your documents (each paragraph as a separate document):",
                value=default_docs,
                height=300,
                placeholder="Paste your documents here..."
            )

            # D√∂k√ºman ekleme
            if st.button("üìö Add Documents", type="primary", use_container_width=True):
                if not rag_system.collection:
                    st.warning("‚ö†Ô∏è Please initialize the system first!")
                else:
                    documents = []
                    metadata_list = []

                    # Y√ºklenen dosyalardan d√∂k√ºmanlarƒ± al
                    if uploaded_files:
                        for file in uploaded_files:
                            content = str(file.read(), "utf-8")
                            documents.append(content)
                            metadata_list.append({
                                "source": file.name,
                                "type": "uploaded_file"
                            })

                    # Manuel girilen d√∂k√ºmanlarƒ± al
                    if documents_text.strip():
                        manual_docs = [doc.strip() for doc in documents_text.split('\n\n') if doc.strip()]
                        documents.extend(manual_docs)
                        for i, doc in enumerate(manual_docs):
                            metadata_list.append({
                                "source": f"manual_input_{i + 1}",
                                "type": "manual_text"
                            })

                    if documents:
                        success = rag_system.upsert_documents(documents, metadata_list)
                        if success:
                            st.success(f"‚úÖ {len(documents)} documents successfully added!")
                            time.sleep(2)
                            st.rerun()
                        else:
                            st.error("‚ùå Document addition failed!")
                    else:
                        st.warning("‚ö†Ô∏è No documents to add!")

        with col2:
            st.header("üí¨ AI-Powered Q&A")

            # Soru giri≈üi
            query = st.text_input(
                "Ask your question:",
                placeholder="Example: What libraries are used for machine learning in Python?",
                key="rag_query"
            )

            if st.button("üîç Get Intelligent Answer", type="primary", use_container_width=True) and query:
                if not rag_system.collection:
                    st.warning("‚ö†Ô∏è Please initialize the system first!")
                elif not rag_system.openrouter_api_key:
                    st.error("‚ùå OpenRouter API key not found! Please set OPENROUTER_API_KEY in .env file.")
                else:
                    # Benzer d√∂k√ºmanlarƒ± ara
                    with st.spinner(f"üîç Searching for relevant information... ({search_type})"):
                        search_results = rag_system.search_similar(
                            query,
                            top_k=search_k,
                            score_threshold=score_threshold,
                            search_type=search_type
                        )

                    if search_results:
                        # Arama performans metrikleri
                        avg_score = sum(r['score'] for r in search_results) / len(search_results)
                        st.markdown(f"""
                        <div class="metric-card">
                            <h3 style="margin: 0; font-size: 1.5rem;">{len(search_results)}</h3>
                            <p style="margin: 0; opacity: 0.9;">Results Found</p>
                            <small>Avg Score: {avg_score:.3f}</small>
                        </div>
                        """, unsafe_allow_html=True)
                        
                        # RAG yanƒ±tƒ± √ºret
                        with st.spinner("ü§ñ Generating intelligent response..."):
                            response = rag_system.generate_rag_response(
                                query, search_results, selected_model
                            )

                        # Sonu√ßlarƒ± g√∂ster
                        st.subheader("üéØ AI Response")
                        st.markdown(f"""
                        <div class="success-message">
                            {response}
                        </div>
                        """, unsafe_allow_html=True)

                        # Kaynak bilgileri
                        with st.expander(f"üìö Sources Used ({len(search_results)} documents)"):
                            for i, result in enumerate(search_results, 1):
                                # Arama tipi badge'i
                                search_type_badge = {
                                    "semantic": "üîç Semantic",
                                    "keyword": "üî§ Keyword", 
                                    "hybrid": "üîÑ Hybrid"
                                }.get(result.get('search_type', 'semantic'), 'üîç')
                                
                                st.write(f"**Source {i}** {search_type_badge} (Score: {result['score']:.3f})")
                                st.write(result['text'])

                                # Metadata bilgileri
                                metadata = result.get('metadata', {})
                                if metadata:
                                    st.caption(f"üìç Source: {metadata.get('source', 'Unknown')} | "
                                               f"Type: {metadata.get('type', 'Unknown')}")
                                st.divider()
                    else:
                        st.warning("‚ö†Ô∏è No relevant information found. Try lowering the similarity threshold.")

        st.markdown('</div>', unsafe_allow_html=True)

    # Tab 2: Data Analytics
    with tab2:
        st.markdown('<div class="tab-content">', unsafe_allow_html=True)
        
        # Help tooltip
        st.markdown("""
        <div class="help-tooltip">
            <strong>üí° Data Analytics:</strong> Upload CSV/Excel files and use natural language to analyze your data. 
            AI will help you understand patterns, create visualizations, and generate insights.
        </div>
        """, unsafe_allow_html=True)
        
        # Session state'de veri saklama
        if "uploaded_data" not in st.session_state:
            st.session_state.uploaded_data = None
        if "data_analysis_history" not in st.session_state:
            st.session_state.data_analysis_history = []
        
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.header("üìÅ Data Upload")
            
            # Modern upload area
            st.markdown("""
            <div class="upload-area">
                <h4>üìä Upload Data Files</h4>
                <p>Drag & drop or click to upload CSV, Excel files</p>
            </div>
            """, unsafe_allow_html=True)
            
            # Dosya y√ºkleme
            uploaded_data_files = st.file_uploader(
                "Choose data files:",
                type=['csv', 'xlsx', 'xls'],
                accept_multiple_files=False,
                key="data_uploader"
            )
            
            # √ñrnek veri olu≈üturma
            st.subheader("üé≤ Sample Data Generator")
            if st.button("üìä Generate Sample Dataset", use_container_width=True):
                # √ñrnek satƒ±≈ü verisi olu≈ütur
                np.random.seed(42)
                dates = pd.date_range('2024-01-01', periods=100, freq='D')
                categories = ['Electronics', 'Clothing', 'Books', 'Home', 'Sports']
                
                sample_data = pd.DataFrame({
                    'Date': dates,
                    'Category': np.random.choice(categories, 100),
                    'Sales_Amount': np.random.normal(1000, 300, 100),
                    'Units_Sold': np.random.poisson(50, 100),
                    'Customer_Rating': np.random.uniform(1, 5, 100).round(1),
                    'Region': np.random.choice(['North', 'South', 'East', 'West'], 100)
                })
                
                st.session_state.uploaded_data = sample_data
                st.success("‚úÖ Sample dataset generated successfully!")
                st.rerun()
            
            # Veri y√ºkleme i≈ülemi
            if uploaded_data_files:
                try:
                    if uploaded_data_files.name.endswith('.csv'):
                        df = pd.read_csv(uploaded_data_files)
                    else:
                        df = pd.read_excel(uploaded_data_files)
                    
                    st.session_state.uploaded_data = df
                    st.success(f"‚úÖ Data loaded successfully! Shape: {df.shape}")
                    
                except Exception as e:
                    st.error(f"‚ùå Error loading data: {e}")
            
            # Y√ºklenen veri √∂zeti
            if st.session_state.uploaded_data is not None:
                df = st.session_state.uploaded_data
                st.subheader("üìã Data Overview")
                
                # Veri √∂zeti
                summary = rag_system.get_data_summary(df)
                if "error" not in summary:
                    col1_metric, col2_metric, col3_metric = st.columns(3)
                    
                    with col1_metric:
                        st.metric("Rows", summary["shape"][0])
                    with col2_metric:
                        st.metric("Columns", summary["shape"][1])
                    with col3_metric:
                        st.metric("Memory (MB)", f"{summary['memory_usage']:.2f}")
                    
                    # Veri √∂nizleme
                    with st.expander("üëÄ Preview Data"):
                        st.dataframe(df.head(10), use_container_width=True)
                    
                    # Veri tipleri
                    with st.expander("üîç Data Types & Missing Values"):
                        col1_type, col2_missing = st.columns(2)
                        
                        with col1_type:
                            st.write("**Data Types:**")
                            for col, dtype in summary["dtypes"].items():
                                st.write(f"‚Ä¢ {col}: {dtype}")
                        
                        with col2_missing:
                            st.write("**Missing Values:**")
                            for col, missing in summary["missing_values"].items():
                                if missing > 0:
                                    st.write(f"‚Ä¢ {col}: {missing}")
                                else:
                                    st.write(f"‚Ä¢ {col}: ‚úÖ Complete")
        
        with col2:
            st.header("ü§ñ AI-Powered Analysis")
            
            if st.session_state.uploaded_data is not None:
                df = st.session_state.uploaded_data
                
                # Doƒüal dil ile analiz
                st.subheader("üí¨ Ask Questions About Your Data")
                
                # √ñrnek sorular
                example_questions = [
                    "Bu veri setinde ka√ß satƒ±r var?",
                    "En y√ºksek satƒ±≈ü miktarƒ± nedir?",
                    "Kategorilere g√∂re ortalama satƒ±≈ü miktarƒ±nƒ± g√∂ster",
                    "B√∂lgelere g√∂re m√º≈üteri puanlarƒ±nƒ± kar≈üƒ±la≈ütƒ±r",
                    "Satƒ±≈ü miktarƒ± ile m√º≈üteri puanƒ± arasƒ±nda korelasyon var mƒ±?"
                ]
                
                # √ñrnek soru se√ßimi
                selected_example = st.selectbox(
                    "üí° Example Questions:",
                    ["Custom Question"] + example_questions,
                    help="Choose an example question or write your own"
                )
                
                if selected_example != "Custom Question":
                    analysis_query = selected_example
                else:
                    analysis_query = st.text_input(
                        "Your analysis question:",
                        placeholder="Example: What is the average sales amount by category?",
                        key="analysis_query"
                    )
                
                if st.button("üîç Analyze with AI", type="primary", use_container_width=True) and analysis_query:
                    #  PI key kontrol√º
                    if not os.getenv("OPENROUTER_API_KEY"):
                        st.error("‚ùåAPI key bulunamadƒ±. L√ºtfen .env dosyasƒ±nda OPENROUTER_API_KEY'i ayarlayƒ±n.")
                    else:
                        # AI analizi yap
                        analysis_result = rag_system.analyze_data_with_pandasai(df, analysis_query)
                        
                        if analysis_result["success"]:
                            # Sonucu g√∂ster
                            st.subheader("üéØ AI Analysis Result")
                            st.markdown(f"""
                            <div class="success-message">
                                {analysis_result["response"]}
                            </div>
                            """, unsafe_allow_html=True)
                            
                            # Analiz ge√ßmi≈üine ekle
                            st.session_state.data_analysis_history.append({
                                "query": analysis_query,
                                "response": analysis_result["response"],
                                "timestamp": datetime.now().strftime("%H:%M:%S")
                            })
                            
                        else:
                            st.error(f"‚ùå Analysis failed: {analysis_result['error']}")
                
                # G√∂rselle≈ütirme √∂nerileri
                st.subheader("üìä Visualization Suggestions")
                suggestions = rag_system.suggest_visualizations(df)
                
                if suggestions:
                    for i, suggestion in enumerate(suggestions[:3]):  # ƒ∞lk 3 √∂neriyi g√∂ster
                        with st.expander(f"üí° {suggestion['title']}"):
                            st.write(suggestion['description'])
                            
                            if st.button(f"Create {suggestion['type'].title()} Chart", key=f"create_{i}"):
                                fig = rag_system.create_visualization(
                                    df, suggestion['type'], suggestion['x_col'], 
                                    suggestion.get('y_col', ''), suggestion['title']
                                )
                                if fig:
                                    st.session_state.current_chart = fig
            
            else:
                st.info("üìÅ Please upload a data file or generate sample data to start analysis.")
        
        # Alt kƒ±sƒ±m - Geli≈ümi≈ü g√∂rselle≈ütirme
        if st.session_state.uploaded_data is not None:
            st.markdown("---")
            st.header("üé® Advanced Visualization")
            
            df = st.session_state.uploaded_data
            
            col1_viz, col2_viz = st.columns(2)
            
            with col1_viz:
                st.subheader("üìà Chart Configuration")
                
                # Grafik tipi se√ßimi
                chart_types = {
                    "Bar Chart": "bar",
                    "Line Chart": "line", 
                    "Scatter Plot": "scatter",
                    "Histogram": "histogram",
                    "Box Plot": "box",
                    "Pie Chart": "pie"
                }
                
                selected_chart = st.selectbox("Chart Type:", list(chart_types.keys()))
                chart_type = chart_types[selected_chart]
                
                # S√ºtun se√ßimi
                available_columns = df.columns.tolist()
                
                if chart_type in ["pie"]:
                    x_col = st.selectbox("Values Column:", available_columns)
                    y_col = None
                else:
                    x_col = st.selectbox("X-Axis Column:", available_columns)
                    y_col = st.selectbox("Y-Axis Column:", available_columns) if chart_type != "histogram" else None
                
                # Renk s√ºtunu (opsiyonel)
                color_col = st.selectbox("Color Column (Optional):", ["None"] + available_columns)
                color_col = None if color_col == "None" else color_col
                
                # Ba≈ülƒ±k
                chart_title = st.text_input("Chart Title:", value=f"{selected_chart} of {x_col}")
                
                if st.button("üé® Create Chart", type="primary"):
                    fig = rag_system.create_visualization(
                        df, chart_type, x_col, y_col, chart_title, color_col
                    )
                    if fig:
                        st.session_state.current_chart = fig
            
            with col2_viz:
                st.subheader("üìä Chart Display")
                
                if "current_chart" in st.session_state:
                    st.plotly_chart(st.session_state.current_chart, use_container_width=True)
                    
                    # Grafik indirme
                    chart_bytes = st.session_state.current_chart.to_image(format="png")
                    st.download_button(
                        label="üì• Download Chart as PNG",
                        data=chart_bytes,
                        file_name=f"chart_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png",
                        mime="image/png"
                    )
                else:
                    st.info("üé® Configure and create a chart to display it here.")
        
        st.markdown('</div>', unsafe_allow_html=True)

    # Alt bilgi
    st.markdown("---")
    
    # Modern footer
    col1, col2, col3 = st.columns([1, 2, 1])
    
    with col1:
        st.markdown("""
        <div style="text-align: center;">
            <h3 style="color: #ff4a4a; margin: 0;">üöÄ TrizRAG</h3>
            <p style="color: #666; font-size: 0.9rem; margin: 0;">AI-Powered Intelligence</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown("""
        <div style="text-align: center; padding: 1rem;">
            <p style="color: #666; margin: 0;">
                <strong>Powered by:</strong> ChromaDB Cloud ‚Ä¢ OpenRouter LLM ‚Ä¢ pandasai
            </p>
            <p style="color: #999; font-size: 0.8rem; margin: 0.5rem 0 0 0;">
                Transform your documents and data into intelligent insights
            </p>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown("""
        <div style="text-align: center;">
            <p style="color: #666; font-size: 0.9rem; margin: 0;">Version 1.0</p>
            <p style="color: #999; font-size: 0.8rem; margin: 0;">¬© 2025 TrizRAG</p>
        </div>
        """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()