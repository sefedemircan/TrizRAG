import streamlit as st
import chromadb
from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction
import openai
from sentence_transformers import SentenceTransformer
import numpy as np
import hashlib
import time
import json
from typing import List, Dict, Any, Tuple
import requests
import os
from datetime import datetime
from dotenv import load_dotenv


# .env dosyasƒ±nƒ± y√ºkle
load_dotenv()

# Sayfa konfig√ºrasyonu
st.set_page_config(
    page_title="TrizRAG - AI-Powered Document Intelligence",
    page_icon="üöÄ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS stilleri
st.markdown("""
<style>
    .main-header {
        background: #ff4a4a;
        padding: 2rem;
        border-radius: 15px;
        margin-bottom: 2rem;
        text-align: center;
        color: white;
    }
    
    .main-header h1 {
        font-size: 3rem;
        font-weight: 700;
        margin-bottom: 0.5rem;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
    }
    
    .main-header p {
        font-size: 1.2rem;
        opacity: 0.9;
        margin-bottom: 0;
    }
    
    .feature-card {
        background: #ff4a4a;
        padding: 1.5rem;
        border-radius: 10px;
        border: 1px solid #e0e0e0;
        box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        margin-bottom: 1rem;
    }
    
    .status-indicator {
        display: inline-block;
        width: 12px;
        height: 12px;
        border-radius: 50%;
        margin-right: 8px;
    }
    
    .status-connected { background-color: #4CAF50; }
    .status-disconnected { background-color: #f44336; }
    .status-loading { background-color: #ff9800; }
    
    .metric-card {
        background: #ff4a4a;
        color: white;
        padding: 1rem;
        border-radius: 10px;
        text-align: center;
        margin: 0.5rem 0;
    }
    
    .help-tooltip {
        
        border-left: 4px solid #ff4a4a;
        padding: 1rem;
        margin: 1rem 0;
        border-radius: 5px;
    }
    
    .success-message {
        background-color: #d4edda;
        border: 1px solid #c3e6cb;
        color: #155724;
        padding: 1rem;
        border-radius: 5px;
        margin: 1rem 0;
    }
    
    .error-message {
        background-color: #f8d7da;
        border: 1px solid #f5c6cb;
        color: #721c24;
        padding: 1rem;
        border-radius: 5px;
        margin: 1rem 0;
    }
    
    .warning-message {
        background-color: #fff3cd;
        border: 1px solid #ffeaa7;
        color: #856404;
        padding: 1rem;
        border-radius: 5px;
        margin: 1rem 0;
    }
    
    .tab-content {
        padding: 1rem 0;
    }
    
    .upload-area {
        border: 1px solid;
        border-radius: 10px;
        padding: 2rem;
        text-align: center;
        transition: all 0.3s ease;
    }
    
    .upload-area:hover {
        border-color: #ff4a4a;
        background-color: #ff4a4a;
        transition: all 0.5s ease;
    }
    }
</style>
""", unsafe_allow_html=True)


class AdvancedRAGSystem:
    def __init__(self):
        self.embedding_model = None
        self.client = None
        self.collection = None
        self.collection_name = "rag-poc-collection"
        # OpenRouter API key'i .env'den otomatik al
        self.openrouter_api_key = os.getenv("OPENROUTER_API_KEY")
        self.dimension = 1024  # all-MiniLM-L6-v2 embedding boyutu
        self.chroma_api_key = os.getenv("CHROMA_API_KEY")
        self.chroma_tenant = os.getenv("CHROMA_TENANT")
        self.chroma_database = os.getenv("CHROMA_DATABASE")
        

    def initialize_chromadb(self):
        """ChromaDB Cloud'u ba≈ülat"""
        try:
            # ChromaDB Cloud client'ƒ± ba≈ülat
            self.client = chromadb.HttpClient(
                ssl=True,
                host='api.trychroma.com',
                tenant=self.chroma_tenant,
                database=self.chroma_database,
                headers={
                    'x-chroma-token': self.chroma_api_key
                }
            )
            
            # Embedding function olu≈ütur
            embedding_function = SentenceTransformerEmbeddingFunction(
                model_name='intfloat/multilingual-e5-large'
            )
            
            # Collection'ƒ± olu≈ütur veya al
            try:
                self.collection = self.client.get_collection(
                    name=self.collection_name,
                    embedding_function=embedding_function
                )
            except:
                self.collection = self.client.create_collection(
                    name=self.collection_name,
                    embedding_function=embedding_function
                )
            
            return True

        except Exception as e:
            st.error(f"ChromaDB Cloud baƒülantƒ± hatasƒ±: {e}")
            return False

    

    @st.cache_resource
    def load_embedding_model(_self):
        """Embedding modelini y√ºkle"""
        try:
            _self.embedding_model = SentenceTransformer('intfloat/multilingual-e5-large')
            return True
        except Exception as e:
            st.error(f"Embedding model y√ºkleme hatasƒ±: {e}")
            return False

    def chunk_text(self, text: str, chunk_size: int = 500, overlap: int = 50) -> List[str]:
        """Metni par√ßalara b√∂l"""
        chunks = []
        start = 0
        text_length = len(text)

        while start < text_length:
            end = start + chunk_size
            if end > text_length:
                end = text_length

            chunk = text[start:end]
            chunks.append(chunk.strip())

            if end == text_length:
                break

            start = end - overlap

        return [chunk for chunk in chunks if len(chunk.strip()) > 10]

    def generate_id(self, text: str) -> str:
        """Metin i√ßin benzersiz ID √ºret"""
        return hashlib.md5(text.encode()).hexdigest()

    def upsert_documents(self, documents: List[str], metadata_list: List[Dict] = None) -> bool:
        """D√∂k√ºmanlarƒ± ChromaDB'ye ekle"""
        if not self.collection:
            return False

        try:
            all_ids = []
            all_documents = []
            all_metadatas = []

            with st.spinner("D√∂k√ºmanlar i≈üleniyor ve vekt√∂rle≈ütiriliyor..."):
                for i, doc in enumerate(documents):
                    # Metni par√ßalara b√∂l
                    chunks = self.chunk_text(doc)

                    for j, chunk in enumerate(chunks):
                        # ID olu≈ütur
                        chunk_id = f"doc_{i}_chunk_{j}_{self.generate_id(chunk)[:8]}"

                        # Metadata hazƒ±rla
                        metadata = {
                            "doc_id": i,
                            "chunk_id": j,
                            "timestamp": datetime.now().isoformat(),
                            "length": len(chunk)
                        }

                        if metadata_list and i < len(metadata_list):
                            metadata.update(metadata_list[i])

                        all_ids.append(chunk_id)
                        all_documents.append(chunk)
                        all_metadatas.append(metadata)

            # ChromaDB'ye ekle
            self.collection.add(
                ids=all_ids,
                documents=all_documents,
                metadatas=all_metadatas
            )

            return True

        except Exception as e:
            st.error(f"D√∂k√ºman ekleme hatasƒ±: {e}")
            return False

    def search_similar(self, query: str, top_k: int = 5, score_threshold: float = 0.5, search_type: str = "semantic") -> List[Dict]:
        """Benzer d√∂k√ºmanlarƒ± ara"""
        if not self.collection:
            return []

        try:
            if search_type == "semantic":
                # Semantic search - embedding tabanlƒ±
                results = self.collection.query(
                    query_texts=[query],
                    n_results=top_k,
                    include=["documents", "metadatas", "distances"]
                )
            elif search_type == "keyword":
                # Keyword search - where clause ile
                results = self.collection.query(
                    query_texts=[query],
                    n_results=top_k,
                    where={"$or": [{"text": {"$contains": word}} for word in query.lower().split() if len(word) > 2]},
                    include=["documents", "metadatas", "distances"]
                )
            elif search_type == "hybrid":
                # Hybrid search - hem semantic hem keyword
                semantic_results = self.collection.query(
                    query_texts=[query],
                    n_results=top_k * 2,  # Daha fazla sonu√ß al
                    include=["documents", "metadatas", "distances"]
                )
                
                keyword_results = self.collection.query(
                    query_texts=[query],
                    n_results=top_k * 2,
                    where={"$or": [{"text": {"$contains": word}} for word in query.lower().split() if len(word) > 2]},
                    include=["documents", "metadatas", "distances"]
                )
                
                # Sonu√ßlarƒ± birle≈ütir ve sƒ±rala
                all_results = []
                
                # Semantic sonu√ßlarƒ± ekle
                if semantic_results['documents'] and semantic_results['documents'][0]:
                    for i, (doc, metadata, distance) in enumerate(zip(
                        semantic_results['documents'][0], 
                        semantic_results['metadatas'][0], 
                        semantic_results['distances'][0]
                    )):
                        similarity_score = max(0.0, 1 - distance)
                        all_results.append({
                            "text": doc,
                            "score": similarity_score * 0.5,  # Semantic aƒüƒ±rlƒ±ƒüƒ±
                            "metadata": metadata,
                            "search_type": "semantic"
                        })
                
                # Keyword sonu√ßlarƒ± ekle
                if keyword_results['documents'] and keyword_results['documents'][0]:
                    for i, (doc, metadata, distance) in enumerate(zip(
                        keyword_results['documents'][0], 
                        keyword_results['metadatas'][0], 
                        keyword_results['distances'][0]
                    )):
                        similarity_score = 1 - distance
                        all_results.append({
                            "text": doc,
                            "score": similarity_score * 0.3,  # Keyword aƒüƒ±rlƒ±ƒüƒ±
                            "metadata": metadata,
                            "search_type": "keyword"
                        })
                
                # Tekrar eden sonu√ßlarƒ± birle≈ütir ve sƒ±rala
                unique_results = {}
                for result in all_results:
                    text_key = result['text'][:100]  # ƒ∞lk 100 karakteri key olarak kullan
                    if text_key not in unique_results:
                        unique_results[text_key] = result
                    else:
                        # Daha y√ºksek skoru al
                        if result['score'] > unique_results[text_key]['score']:
                            unique_results[text_key] = result
                
                # Skora g√∂re sƒ±rala ve top_k kadar al
                sorted_results = sorted(unique_results.values(), key=lambda x: x['score'], reverse=True)
                return [r for r in sorted_results[:top_k] if r['score'] >= score_threshold]
            else:
                # Default semantic search
                results = self.collection.query(
                    query_texts=[query],
                    n_results=top_k,
                    include=["documents", "metadatas", "distances"]
                )

            # Sonu√ßlarƒ± filtrele ve d√ºzenle
            filtered_results = []
            if results['documents'] and results['documents'][0]:
                for i, (doc, metadata, distance) in enumerate(zip(
                    results['documents'][0], 
                    results['metadatas'][0], 
                    results['distances'][0]
                )):
                    # Distance'ƒ± similarity score'a √ßevir (ChromaDB cosine distance kullanƒ±r)
                    similarity_score = 1 - distance  # Cosine distance'ƒ± similarity'e √ßevir
                    
                    if similarity_score >= score_threshold:
                        filtered_results.append({
                            "text": doc,
                            "score": similarity_score,
                            "metadata": metadata,
                            "search_type": search_type
                        })

            return filtered_results

        except Exception as e:
            st.error(f"Arama hatasƒ±: {e}")
            return []

    def call_openrouter_llm(self, prompt: str, model: str = "microsoft/wizardlm-2-8x22b") -> str:
        """OpenRouter API ile LLM √ßaƒürƒ±sƒ±"""
        if not self.openrouter_api_key:
            return "‚ùå OpenRouter API key bulunamadƒ±. L√ºtfen .env dosyasƒ±nda OPENROUTER_API_KEY'i ayarlayƒ±n."

        try:
            headers = {
                "Authorization": f"Bearer {self.openrouter_api_key}",
                "Content-Type": "application/json",
                "HTTP-Referer": "https://streamlit.io",
                "X-Title": "RAG PoC System"
            }

            data = {
                "model": model,
                "messages": [
                    {
                        "role": "system",
                        "content": "Sen yardƒ±mcƒ± bir asistansƒ±n. Verilen bilgileri kullanarak doƒüru, detaylƒ± ve T√ºrk√ße yanƒ±tlar ver."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                "max_tokens": 500,
                "temperature": 0.7
            }

            response = requests.post(
                "https://openrouter.ai/api/v1/chat/completions",
                headers=headers,
                json=data,
                timeout=30
            )

            if response.status_code == 200:
                result = response.json()
                return result["choices"][0]["message"]["content"]
            else:
                return f"‚ùå API Hatasƒ±: {response.status_code} - {response.text}"

        except Exception as e:
            return f"‚ùå LLM √ßaƒürƒ± hatasƒ±: {e}"

    def generate_rag_response(self, query: str, search_results: List[Dict], model: str) -> str:
        """RAG ile yanƒ±t √ºret"""
        if not search_results:
            return "ƒ∞lgili bilgi bulunamadƒ±."

        # Context olu≈ütur
        context_parts = []
        for i, result in enumerate(search_results, 1):
            context_parts.append(f"Kaynak {i}: {result['text']}")

        context = "\n\n".join(context_parts)

        # Prompt olu≈ütur
        prompt = f"""A≈üaƒüƒ±daki kaynaklardaki bilgileri kullanarak soruyu yanƒ±tla:

KAYNAKLAR:
{context}

SORU: {query}

YANIT: Yukarƒ±daki kaynaklardaki bilgileri kullanarak soruyu detaylƒ± bir ≈üekilde yanƒ±tla. Hangi kaynaklarƒ± kullandƒ±ƒüƒ±nƒ± belirt."""

        return self.call_openrouter_llm(prompt, model)

    def get_collection_stats(self) -> Dict:
        """Collection istatistiklerini al"""
        if not self.collection:
            return {}

        try:
            count = self.collection.count()
            return {
                "total_documents": count,
                "collection_name": self.collection_name
            }
        except Exception as e:
            return {"error": str(e)}


# Ana uygulama
def main():
    # Modern Header
    st.markdown("""
    <div class="main-header">
        <h1>üöÄ TrizRAG</h1>
        <p>AI-Powered Document Intelligence & Data Analysis Platform</p>
    </div>
    """, unsafe_allow_html=True)
    
    # RAG sistemi ba≈ülat
    if "rag_system" not in st.session_state:
        st.session_state.rag_system = AdvancedRAGSystem()

    rag_system = st.session_state.rag_system

    # Sidebar - Ayarlar
    with st.sidebar:
        # Logo ve ba≈ülƒ±k
        st.markdown("""
        <div style="text-align: center; padding: 1rem 0;">
            <h2 style="color: #ff4a4a; margin-bottom: 0;">üöÄ TrizRAG</h2>
            <p style="color: #666; font-size: 0.9rem; margin: 0;">Control Panel</p>
        </div>
        """, unsafe_allow_html=True)
        
        st.divider()
        
        # Sistem ba≈ülat
        st.header("‚öôÔ∏è System Setup")
        if st.button("üîÑ Initialize System", type="primary", use_container_width=True):
            with st.spinner("üöÄ Initializing TrizRAG..."):
                # Embedding model y√ºkle
                embedding_success = rag_system.load_embedding_model()
                # ChromaDB ba≈ülat
                chromadb_success = rag_system.initialize_chromadb()
                

                if embedding_success and chromadb_success:
                    st.success("‚úÖ TrizRAG successfully initialized!")
                    st.rerun()
                else:
                    st.error("‚ùå System initialization failed!")

        st.divider()
        
        # Model se√ßimi
        st.header("ü§ñ AI Model Settings")
        available_models = {
            "üöÄ WizardLM-2 8x22B (Free)": "microsoft/wizardlm-2-8x22b",
            "ü¶ô Meta-Llama 3 8B (Free)": "meta-llama/llama-3.2-3b-instruct:free",
            "üåü Google: Gemini 2.5 Pro (Free)": "google/gemini-2.5-pro-exp-03-25",
            "üîç DeepSeek R1 (Free)": "deepseek/deepseek-r1:free"
        }

        selected_model_name = st.selectbox(
            "Select LLM Model:",
            list(available_models.keys())
        )
        selected_model = available_models[selected_model_name]

        # Arama ayarlarƒ±
        st.subheader("üîç Search Configuration")
        
        # Arama tipi se√ßimi
        search_type = st.selectbox(
            "Search Type:",
            ["semantic", "keyword", "hybrid"],
            format_func=lambda x: {
                "semantic": "üîç Semantic (AI-Powered)",
                "keyword": "üî§ Keyword (Text Matching)",
                "hybrid": "üîÑ Hybrid (Best of Both)"
            }[x],
            help="Semantic: AI-powered understanding, Keyword: Exact text matching, Hybrid: Combines both approaches"
        )
        
        search_k = st.slider("Results Count:", 1, 10, 5)
        score_threshold = st.slider("Similarity Threshold:", 0.0, 1.0, 0.5, 0.1)

        st.divider()

        # Sistem durumu
        st.header("üìä System Status")

        # Baƒülantƒ± durumlarƒ±
        chromadb_status = "üü¢ Connected" if rag_system.collection else "üî¥ Disconnected"
        st.markdown(f"""
        <div style="display: flex; align-items: center; margin: 0.5rem 0;">
            <span class="status-indicator {'status-connected' if rag_system.collection else 'status-disconnected'}"></span>
            <span><strong>ChromaDB Cloud:</strong> {chromadb_status}</span>
        </div>
        """, unsafe_allow_html=True)

        embedding_status = "üü¢ Loaded" if rag_system.embedding_model else "üî¥ Not Loaded"
        st.markdown(f"""
        <div style="display: flex; align-items: center; margin: 0.5rem 0;">
            <span class="status-indicator {'status-connected' if rag_system.embedding_model else 'status-disconnected'}"></span>
            <span><strong>Embedding Model:</strong> {embedding_status}</span>
        </div>
        """, unsafe_allow_html=True)

        

        # ChromaDB Cloud bilgileri


        # Collection istatistikleri
        if rag_system.collection:
            stats = rag_system.get_collection_stats()
            if "total_documents" in stats:
                st.markdown(f"""
                <div class="metric-card">
                    <h3 style="margin: 0; font-size: 1.5rem;">{stats['total_documents']}</h3>
                    <p style="margin: 0; opacity: 0.9;">Total Documents</p>
                </div>
                """, unsafe_allow_html=True)
                

        st.divider()
        
        # Help section
        st.header("‚ùì Quick Help")
        with st.expander("How to use TrizRAG"):
            st.markdown("""
            **üöÄ Getting Started:**
            1. Click "Initialize System" to start
            2. Upload documents in RAG tab
            3. Ask questions about your documents
            
            
            **üí° Tips:**
            - Use semantic search for best results
            - Try different AI models for varied responses
            - Upload CSV files for data analysis
            """)

    # Ana i√ßerik - Sekmeli yapƒ±
    tab1, tab2 = st.tabs(["üìö Document Intelligence", "üìä Data Analytics"])
    
    # Tab 1: Document Intelligence (RAG)
    with tab1:
        st.markdown('<div class="tab-content">', unsafe_allow_html=True)
        
        # Help tooltip
        st.markdown("""
        <div class="help-tooltip">
            <strong>üí° Document Intelligence:</strong> Upload documents and ask AI-powered questions. 
            TrizRAG will search through your documents and provide intelligent answers based on the content.
        </div>
        """, unsafe_allow_html=True)
        
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.header("üìÑ Document Management")
            
            # Modern upload area
            st.markdown("""
            <div class="upload-area">
                <h4>üìÅ Upload Documents</h4>
                <p>Drag & drop or click to upload TXT files</p>
            </div>
            """, unsafe_allow_html=True)

            # Dosya y√ºkleme
            uploaded_files = st.file_uploader(
                "Choose files:",
                type=['txt'],
                accept_multiple_files=True,
                label_visibility="collapsed"
            )

            # Manuel d√∂k√ºman giri≈üi
            st.subheader("‚úçÔ∏è Manual Document Input")
            
            # √ñrnek d√∂k√ºmanlar
            default_docs = """Python, yorumlanabilir, etkile≈üimli ve nesne y√∂nelimli bir programlama dilidir. Guido van Rossum tarafƒ±ndan 1991 yƒ±lƒ±nda geli≈ütirilmi≈ütir. Basit s√∂zdizimi ve g√º√ßl√º k√ºt√ºphaneleri sayesinde veri bilimi, web geli≈ütirme, yapay zeka ve otomasyon projelerinde yaygƒ±n olarak kullanƒ±lmaktadƒ±r.

Machine Learning (Makine √ñƒürenmesi), bilgisayarlarƒ±n verilerden √∂ƒürenmesini saƒülayan yapay zeka dalƒ±dƒ±r. Supervised learning (denetimli √∂ƒürenme), unsupervised learning (denetimsiz √∂ƒürenme) ve reinforcement learning (peki≈ütirmeli √∂ƒürenme) olmak √ºzere √º√ß ana kategoriye ayrƒ±lƒ±r. Scikit-learn, TensorFlow ve PyTorch gibi k√ºt√ºphaneler ML projelerinde sƒ±k√ßa kullanƒ±lƒ±r.

RAG (Retrieval-Augmented Generation), b√ºy√ºk dil modellerinin performansƒ±nƒ± artƒ±rmak i√ßin kullanƒ±lan bir tekniktir. √ñnce ilgili bilgiyi bir vekt√∂r veritabanƒ±ndan alƒ±r, sonra bu bilgiyi context olarak kullanarak LLM ile yanƒ±t √ºretir. Bu sayede modelin bilgi g√ºncelliƒüi ve doƒüruluƒüu artar.

Pinecone, y√ºksek performanslƒ± vekt√∂r veritabanƒ± hizmetidir. Similarity search ve recommendation sistemlerinde kullanƒ±lƒ±r. Serverless mimarisi sayesinde √∂l√ßeklenebilir ve y√∂netimi kolaydƒ±r. √úcretsiz tier ile ba≈ülayƒ±p, ihtiyaca g√∂re √ºcretli planlara ge√ßilebilir.

OpenRouter, farklƒ± AI modellerine tek bir API √ºzerinden eri≈üim saƒülayan platformdur. GPT, Claude, Llama gibi √ße≈üitli modelleri destekler. √úcretsiz tier ile deneme imkanƒ± sunar ve pay-per-use modeliyle maliyet kontrol√º saƒülar."""

            documents_text = st.text_area(
                "Enter your documents (each paragraph as a separate document):",
                value=default_docs,
                height=300,
                placeholder="Paste your documents here..."
            )

            # D√∂k√ºman ekleme
            if st.button("üìö Add Documents", type="primary", use_container_width=True):
                if not rag_system.collection:
                    st.warning("‚ö†Ô∏è Please initialize the system first!")
                else:
                    documents = []
                    metadata_list = []

                    # Y√ºklenen dosyalardan d√∂k√ºmanlarƒ± al
                    if uploaded_files:
                        for file in uploaded_files:
                            content = str(file.read(), "utf-8")
                            documents.append(content)
                            metadata_list.append({
                                "source": file.name,
                                "type": "uploaded_file"
                            })

                    # Manuel girilen d√∂k√ºmanlarƒ± al
                    if documents_text.strip():
                        manual_docs = [doc.strip() for doc in documents_text.split('\n\n') if doc.strip()]
                        documents.extend(manual_docs)
                        for i, doc in enumerate(manual_docs):
                            metadata_list.append({
                                "source": f"manual_input_{i + 1}",
                                "type": "manual_text"
                            })

                    if documents:
                        success = rag_system.upsert_documents(documents, metadata_list)
                        if success:
                            st.success(f"‚úÖ {len(documents)} documents successfully added!")
                            time.sleep(2)
                            st.rerun()
                        else:
                            st.error("‚ùå Document addition failed!")
                    else:
                        st.warning("‚ö†Ô∏è No documents to add!")

        with col2:
            st.header("üí¨ AI-Powered Q&A")

            # Soru giri≈üi
            query = st.text_input(
                "Ask your question:",
                placeholder="Example: What libraries are used for machine learning in Python?",
                key="rag_query"
            )

            if st.button("üîç Get Intelligent Answer", type="primary", use_container_width=True) and query:
                if not rag_system.collection:
                    st.warning("‚ö†Ô∏è Please initialize the system first!")
                elif not rag_system.openrouter_api_key:
                    st.error("‚ùå OpenRouter API key not found! Please set OPENROUTER_API_KEY in .env file.")
                else:
                    # Benzer d√∂k√ºmanlarƒ± ara
                    with st.spinner(f"üîç Searching for relevant information... ({search_type})"):
                        search_results = rag_system.search_similar(
                            query,
                            top_k=search_k,
                            score_threshold=score_threshold,
                            search_type=search_type
                        )

                    if search_results:
                        # Arama performans metrikleri
                        avg_score = sum(r['score'] for r in search_results) / len(search_results)
                        st.markdown(f"""
                        <div class="metric-card">
                            <h3 style="margin: 0; font-size: 1.5rem;">{len(search_results)}</h3>
                            <p style="margin: 0; opacity: 0.9;">Results Found</p>
                            <small>Avg Score: {avg_score:.3f}</small>
                        </div>
                        """, unsafe_allow_html=True)
                        
                        # RAG yanƒ±tƒ± √ºret
                        with st.spinner("ü§ñ Generating intelligent response..."):
                            response = rag_system.generate_rag_response(
                                query, search_results, selected_model
                            )

                        # Sonu√ßlarƒ± g√∂ster
                        st.subheader("üéØ AI Response")
                        st.markdown(f"""
                        <div class="success-message">
                            {response}
                        </div>
                        """, unsafe_allow_html=True)

                        # Kaynak bilgileri
                        with st.expander(f"üìö Sources Used ({len(search_results)} documents)"):
                            for i, result in enumerate(search_results, 1):
                                # Arama tipi badge'i
                                search_type_badge = {
                                    "semantic": "üîç Semantic",
                                    "keyword": "üî§ Keyword", 
                                    "hybrid": "üîÑ Hybrid"
                                }.get(result.get('search_type', 'semantic'), 'üîç')
                                
                                st.write(f"**Source {i}** {search_type_badge} (Score: {result['score']:.3f})")
                                st.write(result['text'])

                                # Metadata bilgileri
                                metadata = result.get('metadata', {})
                                if metadata:
                                    st.caption(f"üìç Source: {metadata.get('source', 'Unknown')} | "
                                               f"Type: {metadata.get('type', 'Unknown')}")
                                st.divider()
                    else:
                        st.warning("‚ö†Ô∏è No relevant information found. Try lowering the similarity threshold.")

        st.markdown('</div>', unsafe_allow_html=True)

    # Alt bilgi
    st.markdown("---")
    
    # Modern footer
    col1, col2, col3 = st.columns([1, 2, 1])
    
    with col1:
        st.markdown("""
        <div style="text-align: center;">
            <h3 style="color: #ff4a4a; margin: 0;">üöÄ TrizRAG</h3>
            <p style="color: #666; font-size: 0.9rem; margin: 0;">AI-Powered Intelligence</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown("""
        <div style="text-align: center; padding: 1rem;">
            <p style="color: #666; margin: 0;">
                <strong>Powered by:</strong> ChromaDB Cloud ‚Ä¢ OpenRouter LLM ‚Ä¢ pandasai
            </p>
            <p style="color: #999; font-size: 0.8rem; margin: 0.5rem 0 0 0;">
                Transform your documents and data into intelligent insights
            </p>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown("""
        <div style="text-align: center;">
            <p style="color: #666; font-size: 0.9rem; margin: 0;">Version 1.0</p>
            <p style="color: #999; font-size: 0.8rem; margin: 0;">¬© 2025 TrizRAG</p>
        </div>
        """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()